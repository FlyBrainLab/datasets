{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading NeuroArch Database with Hemibrain Dataset v1.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial provides code to load NeuroArch database with Hemibrain Dataset v1.0.1. Requirement before running the notebook:\n",
    "- Installed [NeuroArch](https://github.com/fruitflybrain/neuroarch), [OrientDB Community Version](https://www.orientdb.org/download), and [pyorient](https://github.com/fruitflybrain/pyorient). The [NeuroNLP Docker image](https://hub.docker.com/r/fruitflybrain/neuronlp) and [FlyBrainLab Docker image](https://hub.docker.com/r/fruitflybrain/fbl) all have a copy of the software requirement ready.\n",
    "- Installed [PyMeshLab](https://pypi.org/project/pymeshlab/).\n",
    "- Installed [neuprint-python](https://github.com/connectome-neuprint/neuprint-python).\n",
    "- Download the [Neuprint database dump for the Hemibrain dataset v1.0.1](https://storage.cloud.google.com/hemibrain-release/neuprint/hemibrain_v1.0.1_neo4j_inputs.zip).\n",
    "- Have the [token](https://connectome-neuprint.github.io/neuprint-python/docs/client.html#neuprint.client.Client) for Neuprint HTTP access ready.\n",
    "- Have more than 60 GB free disk space (for Neuprint dump and NeuroArch database).\n",
    "\n",
    "A backup of the database created by this notebook can be downloaded [here](https://drive.google.com/file/d/1x6MQJB_4OaWJR6d6O3WFCSeJWG58FsPT/view?usp=sharing). To restore it in OrientDB, run\n",
    "```\n",
    "/path/to/orientdb/bin/console.sh \"create database plocal:../databases/hemibrain admin admin; restore database /path/to/hemibrain1.0.1_na_v1.0_backup.zip\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import subprocess\n",
    "import csv\n",
    "import json\n",
    "import warnings\n",
    "from requests import HTTPError\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from neuprint import Client\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import pymeshlab as ml\n",
    "import neuroarch.na as na\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Brain Region\n",
    "First define all brain regions in the hemibrain data, and assign them as subsystem, neuropil or subregions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_brain_regions = \\\n",
    "{'OL(R)': {'System': 'OL(R)', 'Neuropil': None, 'Subregions': None},\n",
    "'MB(R)': {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': None},\n",
    "'MB(L)': {'System': 'MB(+ACA)(L)', 'Neuropil': 'MB(L)', 'Subregions': None},\n",
    "'CX': {'System': 'CX', 'Neuropil': None, 'Subregions': None},\n",
    "'LX(R)': {'System': 'LX(R)', 'Neuropil': None, 'Subregions': None},\n",
    "'LX(L)': {'System': 'LX(L)', 'Neuropil': None, 'Subregions': None},\n",
    "'VLNP(R)': {'System': 'VLNP(R)', 'Neuropil': None, 'Subregions': None},\n",
    "'LH(R)': {'System': 'LH(R)', 'Neuropil': 'LH(R)', 'Subregions': None},\n",
    "'SNP(R)': {'System': 'SNP(R)', 'Neuropil': None, 'Subregions': None},\n",
    "'SNP(L)': {'System': 'SNP(L)', 'Neuropil': None, 'Subregions': None},\n",
    "'INP': {'System': 'INP', 'Neuropil': None, 'Subregions': None},\n",
    "'AL(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': None},\n",
    "'AL(L)': {'System': 'AL(L)', 'Neuropil': 'AL(L)', 'Subregions': None},\n",
    "'VMNP': {'System': 'VMNP', 'Neuropil': None, 'Subregions': None},\n",
    "'PENP': {'System': 'PENP', 'Neuropil': None, 'Subregions': None},\n",
    "'GNG': {'System': 'GNG', 'Neuropil': 'GNG', 'Subregions': None},\n",
    "'AOT(R)': {'Tract': 'AOT(R)', 'Neuropil': None, 'Subregions': None},\n",
    "'GC': {'Tract': 'GC', 'Neuropil': None, 'Subregions': None},\n",
    "'GF(R)': {'Tract': 'GF(R)', 'Neuropil': None, 'Subregions': None},\n",
    "'mALT(R)': {'Tract': 'mALT(R)', 'Neuropil': None, 'Subregions': None},\n",
    "'mALT(L)': {'Tract': 'mALT(L)', 'Neuropil': None, 'Subregions': None},\n",
    "'POC': {'Tract': 'POC', 'Neuropil': None, 'Subregions': None},\n",
    "'ME(R)': {'System': 'OL(R)', 'Neuropil': 'ME(R)', 'Subregions': None},\n",
    "'AME(R)': {'System': 'OL(R)', 'Neuropil': 'AME(R)', 'Subregions': None},\n",
    "'CA(R)': {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': 'CA(R)'},\n",
    "'CA(L)': {'System': 'MB(+ACA)(L)', 'Neuropil': 'MB(L)', 'Subregions': 'CA(L)'},\n",
    "'dACA(R)': {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': 'dACA(R)'},\n",
    "'lACA(R)': {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': 'lACA(R)'},\n",
    "'vACA(R)': {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': 'vACA(R)'},\n",
    "'PED(R)': {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': 'PED(R)'},\n",
    "'CB': {'System': 'CX', 'Neuropil': ['FB', 'EB'], 'Subregions': None},\n",
    "'PB': {'System': 'CX', 'Neuropil': 'PB', 'Subregions': None},\n",
    "'NO': {'System': 'CX', 'Neuropil': ['NO(R)', 'NO(L)'], 'Subregions': None},\n",
    "'BU(R)': {'System': 'LX(R)', 'Neuropil': 'BU(R)', 'Subregions': None},\n",
    "'BU(L)': {'System': 'LX(L)', 'Neuropil': 'BU(L)', 'Subregions': None},\n",
    "'LAL(R)': {'System': 'LX(R)', 'Neuropil': 'LAL(R)', 'Subregions': None},\n",
    "'LAL(L)': {'System': 'LX(L)', 'Neuropil': 'LAL(L)', 'Subregions': None},\n",
    "'AOTU(R)': {'System': 'VLNP(R)', 'Neuropil': 'AOTU(R)', 'Subregions': None},\n",
    "'PLP(R)': {'System': 'VLNP(R)', 'Neuropil': 'PLP(R)', 'Subregions': None},\n",
    "'WED(R)': {'System': 'VLNP(R)', 'Neuropil': 'WED(R)', 'Subregions': None},\n",
    "'SLP(R)': {'System': 'SNP(R)', 'Neuropil': 'SLP(R)', 'Subregions': None},\n",
    "'SIP(R)': {'System': 'SNP(R)', 'Neuropil': 'SIP(R)', 'Subregions': None},\n",
    "'SIP(L)': {'System': 'SNP(L)', 'Neuropil': 'SIP(L)', 'Subregions': None},\n",
    "'SMP(R)': {'System': 'SNP(R)', 'Neuropil': 'SMP(R)', 'Subregions': None},\n",
    "'SMP(L)': {'System': 'SNP(L)', 'Neuropil': 'SMP(L)', 'Subregions': None},\n",
    "'CRE(R)': {'System': 'INP', 'Neuropil': 'CRE(R)', 'Subregions': None},\n",
    "'CRE(L)': {'System': 'INP', 'Neuropil': 'CRE(L)', 'Subregions': None},\n",
    "'IB': {'System': 'INP', 'Neuropil': 'IB', 'Subregions': None},\n",
    "'ATL(R)': {'System': 'INP', 'Neuropil': 'ATL(R)', 'Subregions': None},\n",
    "'ATL(L)': {'System': 'INP', 'Neuropil': 'ATL(L)', 'Subregions': None},\n",
    "'AL-DC3(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-DC3(R)'},\n",
    "'SAD': {'System': 'PENP', 'Neuropil': 'SAD', 'Subregions': None},\n",
    "'FLA(R)': {'System': 'PENP', 'Neuropil': 'FLA(R)', 'Subregions': None},\n",
    "'CAN(R)': {'System': 'PENP', 'Neuropil': 'CAN(R)', 'Subregions': None},\n",
    "'PRW': {'System': 'PENP', 'Neuropil': 'PRW', 'Subregions': None},\n",
    "'LO(R)': {'System': 'OL(R)', 'Neuropil': 'LO(R)', 'Subregions': None},\n",
    "'LOP(R)': {'System': 'OL(R)', 'Neuropil': 'LOP(R)', 'Subregions': None},\n",
    "\"a'L(R)\": {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': \"a'L(R)\"},\n",
    "\"a'1(R)\": {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': \"a'1(R)\"},\n",
    "\"a'2(R)\": {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': \"a'2(R)\"},\n",
    "\"a'3(R)\": {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': \"a'3(R)\"},\n",
    "\"a'L(L)\": {'System': 'MB(+ACA)(L)', 'Neuropil': 'MB(L)', 'Subregions': \"a'L(L)\"},\n",
    "'aL(R)': {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': 'aL(R)'},\n",
    "'a1(R)': {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': 'a1(R)'},\n",
    "'a2(R)': {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': 'a2(R)'},\n",
    "'a3(R)': {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': 'a3(R)'},\n",
    "'aL(L)': {'System': 'MB(+ACA)(L)', 'Neuropil': 'MB(L)', 'Subregions': 'aL(L)'},\n",
    "'gL(R)': {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': 'gL(R)'},\n",
    "'g1(R)': {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': 'g1(R)'},\n",
    "'g2(R)': {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': 'g2(R)'},\n",
    "'g3(R)': {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': 'g3(R)'},\n",
    "'g4(R)': {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': 'g4(R)'},\n",
    "'g5(R)': {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': 'g5(R)'},\n",
    "'gL(L)': {'System': 'MB(+ACA)(L)', 'Neuropil': 'MB(L)', 'Subregions': 'gL(L)'},\n",
    "\"b'L(R)\": {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': \"b'L(R)\"},\n",
    "\"b'1(R)\": {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': \"b'1(R)\"},\n",
    "\"b'2(R)\": {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': \"b'2(R)\"},\n",
    "\"b'L(L)\": {'System': 'MB(+ACA)(L)', 'Neuropil': 'MB(L)', 'Subregions': \"b'L(L)\"},\n",
    "'bL(R)': {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': 'bL(R)'},\n",
    "'b1(R)': {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': 'b1(R)'},\n",
    "'b2(R)': {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': 'b2(R)'},\n",
    "'bL(L)': {'System': 'MB(+ACA)(L)', 'Neuropil': 'MB(L)', 'Subregions': 'bL(L)'},\n",
    "'FB': {'System': 'CX', 'Neuropil': 'FB', 'Subregions': None},\n",
    "'FBl1': {'System': 'CX', 'Neuropil': 'FB', 'Subregions': 'FBl1'},\n",
    "'FBl2': {'System': 'CX', 'Neuropil': 'FB', 'Subregions': 'FBl2'},\n",
    "'FBl3': {'System': 'CX', 'Neuropil': 'FB', 'Subregions': 'FBl3'},\n",
    "'FBl4': {'System': 'CX', 'Neuropil': 'FB', 'Subregions': 'FBl4'},\n",
    "'FBl5': {'System': 'CX', 'Neuropil': 'FB', 'Subregions': 'FBl5'},\n",
    "'FBl6': {'System': 'CX', 'Neuropil': 'FB', 'Subregions': 'FBl6'},\n",
    "'FBl7': {'System': 'CX', 'Neuropil': 'FB', 'Subregions': 'FBl7'},\n",
    "'FBl8': {'System': 'CX', 'Neuropil': 'FB', 'Subregions': 'FBl8'},\n",
    "'FBl9': {'System': 'CX', 'Neuropil': 'FB', 'Subregions': 'FBl9'},\n",
    "'EB': {'System': 'CX', 'Neuropil': 'EB', 'Subregions': None},\n",
    "'EBr1': {'System': 'CX', 'Neuropil': 'EB', 'Subregions': 'EBr1'},\n",
    "'EBr2r4': {'System': 'CX', 'Neuropil': 'EB', 'Subregions': 'EBr2r4'},\n",
    "'EBr3am': {'System': 'CX', 'Neuropil': 'EB', 'Subregions': 'EBr3am'},\n",
    "'EBr3d': {'System': 'CX', 'Neuropil': 'EB', 'Subregions': 'EBr3d'},\n",
    "'EBr3pw': {'System': 'CX', 'Neuropil': 'EB', 'Subregions': 'EBr3pw'},\n",
    "'EBr5': {'System': 'CX', 'Neuropil': 'EB', 'Subregions': 'EBr5'},\n",
    "'EBr6': {'System': 'CX', 'Neuropil': 'EB', 'Subregions': 'EBr6'},\n",
    "'PB(R1)': {'System': 'CX', 'Neuropil': 'PB', 'Subregions': 'PB(R1)'},\n",
    "'PB(R2)': {'System': 'CX', 'Neuropil': 'PB', 'Subregions': 'PB(R2)'},\n",
    "'PB(R3)': {'System': 'CX', 'Neuropil': 'PB', 'Subregions': 'PB(R3)'},\n",
    "'PB(R4)': {'System': 'CX', 'Neuropil': 'PB', 'Subregions': 'PB(R4)'},\n",
    "'PB(R5)': {'System': 'CX', 'Neuropil': 'PB', 'Subregions': 'PB(R5)'},\n",
    "'PB(R6)': {'System': 'CX', 'Neuropil': 'PB', 'Subregions': 'PB(R6)'},\n",
    "'PB(R7)': {'System': 'CX', 'Neuropil': 'PB', 'Subregions': 'PB(R7)'},\n",
    "'PB(R8)': {'System': 'CX', 'Neuropil': 'PB', 'Subregions': 'PB(R8)'},\n",
    "'PB(R9)': {'System': 'CX', 'Neuropil': 'PB', 'Subregions': 'PB(R9)'},\n",
    "'PB(L1)': {'System': 'CX', 'Neuropil': 'PB', 'Subregions': 'PB(L1)'},\n",
    "'PB(L2)': {'System': 'CX', 'Neuropil': 'PB', 'Subregions': 'PB(L2)'},\n",
    "'PB(L3)': {'System': 'CX', 'Neuropil': 'PB', 'Subregions': 'PB(L3)'},\n",
    "'PB(L4)': {'System': 'CX', 'Neuropil': 'PB', 'Subregions': 'PB(L4)'},\n",
    "'PB(L5)': {'System': 'CX', 'Neuropil': 'PB', 'Subregions': 'PB(L5)'},\n",
    "'PB(L6)': {'System': 'CX', 'Neuropil': 'PB', 'Subregions': 'PB(L6)'},\n",
    "'PB(L7)': {'System': 'CX', 'Neuropil': 'PB', 'Subregions': 'PB(L7)'},\n",
    "'PB(L8)': {'System': 'CX', 'Neuropil': 'PB', 'Subregions': 'PB(L8)'},\n",
    "'PB(L9)': {'System': 'CX', 'Neuropil': 'PB', 'Subregions': 'PB(L9)'},\n",
    "'NO(R)': {'System': 'CX', 'Neuropil': 'NO(R)', 'Subregions': None},\n",
    "'NO(L)': {'System': 'CX', 'Neuropil': 'NO(L)', 'Subregions': None},\n",
    "'GA(R)': {'System': 'LX(R)', 'Neuropil': 'LAL(R)', 'Subregions': 'GA(R)'},\n",
    "'AVLP(R)': {'System': 'VLNP(R)', 'Neuropil': 'AVLP(R)', 'Subregions': None},\n",
    "'PVLP(R)': {'System': 'VLNP(R)', 'Neuropil': 'PVLP(R)', 'Subregions': None},\n",
    "'RUB(R)': {'System': 'INP', 'Neuropil': 'CRE(R)', 'Subregions': 'RUB(R)'},\n",
    "'RUB(L)': {'System': 'INP', 'Neuropil': 'CRE(L)', 'Subregions': 'RUB(L)'},\n",
    "'ROB(R)': {'System': 'INP', 'Neuropil': 'CRE(R)', 'Subregions': 'ROB(R)'},\n",
    "'SCL(R)': {'System': 'INP', 'Neuropil': 'SCL(R)', 'Subregions': None},\n",
    "'SCL(L)': {'System': 'INP', 'Neuropil': 'SCL(L)', 'Subregions': None},\n",
    "'ICL(R)': {'System': 'INP', 'Neuropil': 'ICL(R)', 'Subregions': None},\n",
    "'ICL(L)': {'System': 'INP', 'Neuropil': 'ICL(L)', 'Subregions': None},\n",
    "'VES(R)': {'System': 'VMNP', 'Neuropil': 'VES(R)', 'Subregions': None},\n",
    "'VES(L)': {'System': 'VMNP', 'Neuropil': 'VES(L)', 'Subregions': None},\n",
    "'EPA(R)': {'System': 'VMNP', 'Neuropil': 'EPA(R)', 'Subregions': None},\n",
    "'EPA(L)': {'System': 'VMNP', 'Neuropil': 'EPA(L)', 'Subregions': None},\n",
    "'GOR(R)': {'System': 'VMNP', 'Neuropil': 'GOR(R)', 'Subregions': None},\n",
    "'GOR(L)': {'System': 'VMNP', 'Neuropil': 'GOR(L)', 'Subregions': None},\n",
    "'SPS(R)': {'System': 'VMNP', 'Neuropil': 'SPS(R)', 'Subregions': None},\n",
    "'SPS(L)': {'System': 'VMNP', 'Neuropil': 'SPS(L)', 'Subregions': None},\n",
    "'IPS(R)': {'System': 'VMNP', 'Neuropil': 'IPS(R)', 'Subregions': None},\n",
    "'AMMC': {'System': 'PENP', 'Neuropil': 'SAD', 'Subregions': 'AMMC'},\n",
    "'AB(R)': {'System': 'CX', 'Neuropil': 'AB(R)', 'Subregions': None},\n",
    "'AB(L)': {'System': 'CX', 'Neuropil': 'AB(L)', 'Subregions': None},\n",
    "'FB-column3': {'System': 'CX', 'Neuropil': 'FB', 'Subregions': 'FB-column3'},\n",
    "'NO1(R)': {'System': 'CX', 'Neuropil': 'NO(R)', 'Subregions': 'NO1(R)'},\n",
    "'NO1(L)': {'System': 'CX', 'Neuropil': 'NO(L)', 'Subregions': 'NO1(L)'},\n",
    "'NO2(R)': {'System': 'CX', 'Neuropil': 'NO(R)', 'Subregions': 'NO2(R)'},\n",
    "'NO2(L)': {'System': 'CX', 'Neuropil': 'NO(L)', 'Subregions': 'NO2(L)'},\n",
    "'NO3(R)': {'System': 'CX', 'Neuropil': 'NO(R)', 'Subregions': 'NO3(R)'},\n",
    "'NO3(L)': {'System': 'CX', 'Neuropil': 'NO(L)', 'Subregions': 'NO3(L)'},\n",
    "'MB(+ACA)(R)': {'System': 'MB(+ACA)(R)', 'Neuropil': None, 'Subregions': None},\n",
    "'MB(+ACA)(L)': {'System': 'MB(+ACA)(L)', 'Neuropil': None, 'Subregions': None},\n",
    "'LAL(-GA)(R)': {'System': 'LX(R)', 'Neuropil': 'LAL(R)', 'Subregions': 'LAL(-GA)(R)'},\n",
    "'SAD(-AMMC)': {'System': 'PENP', 'Neuropil': 'SAD', 'Subregions': 'SAD(-AMMC)'},\n",
    "'CRE(-ROB,-RUB)(R)': {'System': 'INP', 'Neuropil': 'CRE(R)', 'Subregions': 'CRE(-ROB,-RUB)(R)'},\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract from neuprint server the mesh files defining the boundary of these regions. The subsystems do not have mesh. You will need to put your token here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    os.mkdir('roi')\n",
    "except FileExistsError:\n",
    "    warnings.warn('folder roi already exists.')\n",
    "    pass\n",
    "\n",
    "token = ''\n",
    "c = Client('neuprint.janelia.org', dataset='hemibrain:v1.0.1', token=token)\n",
    "for region in all_brain_regions:\n",
    "    try:\n",
    "        c.fetch_roi_mesh(region, 'roi/{}.obj'.format(region))\n",
    "    except:\n",
    "        print(region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Neuron Attributes\n",
    "In the next two cells, we extract from the database dump all the *Traced* neurons and write them into 'neurons.csv' file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(chunk):\n",
    "    status = np.nonzero(np.array([i == 'Traced' for i in chunk['status:string'].values]))[0]\n",
    "    used = chunk.iloc[status]\n",
    "    neurons = []\n",
    "\n",
    "    for i, row in used.iterrows():\n",
    "        neuropil_list = []\n",
    "        subregion_list = []\n",
    "        tract_list = []\n",
    "        kk = json.loads(row['roiInfo:string'])\n",
    "        for k, v in kk.items():\n",
    "            if k == \"None\": continue\n",
    "            region = all_brain_regions[k]\n",
    "            if region['Subregions'] is None:\n",
    "                if region['Neuropil'] is None:\n",
    "                    if 'Tract' in region:\n",
    "                        tract_list.append('{}:{}:{}'.format(\n",
    "                            region['Tract'], v.get('pre',0), v.get('post',0)))\n",
    "                    else:\n",
    "                        continue\n",
    "                elif isinstance(region['Neuropil'], list):\n",
    "                    continue\n",
    "                else:\n",
    "                    neuropil_list.append('{}:{}:{}'.format(\n",
    "                        region['Neuropil'], v.get('pre', 0), v.get('post', 0)))\n",
    "            else:\n",
    "                subregion_list.append('{}:{}:{}'.format(\n",
    "                    region['Subregions'], v.get('pre', 0), v.get('post', 0)))\n",
    "\n",
    "        neuropil_list = ';'.join(neuropil_list)\n",
    "        subregion_list = ';'.join(subregion_list)\n",
    "        tract_list = ';'.join(tract_list)\n",
    "\n",
    "        li = [row['bodyId:long'], row['pre:int'], row['post:int'], row['status:string'],\\\n",
    "              row['statusLabel:string'], int(row['cropped:boolean']) if not np.isnan(row['cropped:boolean']) else row['cropped:boolean'], row['instance:string'], \\\n",
    "              row['type:string'], row['cellBodyFiber:string'], row['somaLocation:point{srid:9157}'], \\\n",
    "              row['somaRadius:float'], row['size:long'], neuropil_list, subregion_list,tract_list]\n",
    "        neurons.append(li)\n",
    "    return neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize = 100000\n",
    "\n",
    "with open('neurons.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['bodyID','pre','post','status','statusLabel','cropped','instance','type','cellBodyFiber','somaLocation','somaRadius','size','neuropils','subregions','tracts'])\n",
    "    for chunk in tqdm(pd.read_csv('hemibrain_v1.0.1_neo4j_inputs/Neuprint_Neurons_52a133.csv', chunksize=chunksize)):\n",
    "        neurons = process(chunk)\n",
    "        writer.writerows(neurons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download the SWC files for all the traced neurons into folder 'swc', we can run the code below uncommented, or download it from [here](https://drive.google.com/file/d/1nhVABRX0cwQc3sXOoAx2EvWKbIYsoFPm/view?usp=sharing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# try: \n",
    "#     os.mkdir('swc')\n",
    "# except FileExistsError:\n",
    "#     warnings.warn('folder roi already exists.')\n",
    "#     pass\n",
    "\n",
    "# neurons = pd.read_csv('neurons.csv')\n",
    "\n",
    "# for i, row in tqdm(neurons.iterrows()):\n",
    "#     bodyID = int(row['bodyID'])\n",
    "#     try:\n",
    "#         s = c.fetch_skeleton(bodyID, format='pandas')\n",
    "#         s.to_csv('swc/{}.swc'.format(bodyID), header=False, index=False, sep=' ')\n",
    "#     except HTTPError:\n",
    "#         print(bodyID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Synapses\n",
    "We only use the neurons that are traced, or roughly traced, or has a name/instance assigned to it. Only synapses between these neurons are extracted below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = pd.read_csv('neurons.csv')\n",
    "used = []\n",
    "for i, row in neurons.iterrows():\n",
    "    if row['statusLabel'] in ['Traced', 'Roughly traced'] or isinstance(row['instance'], str) or isinstance(row['type'], str):\n",
    "        used.append(i)\n",
    "        \n",
    "traced_neuron_id = neurons.iloc[used]['bodyID'].to_numpy()\n",
    "        \n",
    "chunksize = 1000000\n",
    "pre_syn = np.empty((int(1e8),3), np.int64)\n",
    "post_syn = np.empty((int(1e8),3), np.int64)\n",
    "\n",
    "pre_count = 0\n",
    "post_count = 0\n",
    "count = 0\n",
    "for chunk in pd.read_csv('hemibrain_v1.0.1_neo4j_inputs/Neuprint_SynapseSet_to_Synapses_52a133.csv', chunksize=chunksize):\n",
    "    ids = chunk[':START_ID']\n",
    "    pre_site = np.array([[n, int(i.split('_')[0]), int(i.split('_')[1])] \\\n",
    "                         for n,i in enumerate(ids) if i.split('_')[2] == 'pre'])\n",
    "    post_site = np.array([[n, int(i.split('_')[0]), int(i.split('_')[1])] \\\n",
    "                          for n,i in enumerate(ids) if i.split('_')[2] == 'post'])\n",
    "    pre_site_known = pre_site[np.logical_and(\n",
    "                              np.isin(pre_site[:,1], traced_neuron_id),\n",
    "                              np.isin(pre_site[:,2], traced_neuron_id)),0]\n",
    "    post_site_known = post_site[np.logical_and(\n",
    "                                np.isin(post_site[:,1], traced_neuron_id),\n",
    "                                np.isin(post_site[:,2], traced_neuron_id)),0]\n",
    "    retrieved_pre_site = chunk.iloc[pre_site_known]\n",
    "    pre_site = np.array([[row[':END_ID(Syn-ID)'], int(row[':START_ID'].split('_')[0]), int(row[':START_ID'].split('_')[1])] \\\n",
    "                         for i, row in retrieved_pre_site.iterrows()])\n",
    "    retrieved_post_site = chunk.iloc[post_site_known]\n",
    "    post_site = np.array([[row[':END_ID(Syn-ID)'], int(row[':START_ID'].split('_')[0]), int(row[':START_ID'].split('_')[1])] \\\n",
    "                         for i, row in retrieved_post_site.iterrows()])\n",
    "    if pre_site.size:\n",
    "        pre_syn[pre_count:pre_count+pre_site.shape[0], :] = pre_site\n",
    "        pre_count += pre_site.shape[0]\n",
    "    if post_site.size:\n",
    "        post_syn[post_count:post_count+post_site.shape[0], :] = post_site\n",
    "        post_count += post_site.shape[0]\n",
    "    count += chunksize\n",
    "    print(count, pre_count, post_count)\n",
    "\n",
    "pre_syn = pre_syn[:pre_count,:]\n",
    "post_syn = post_syn[:post_count,:]\n",
    "\n",
    "ind = np.argsort(pre_syn[:,0])\n",
    "pre_syn_sorted = pre_syn[ind, :]\n",
    "ind = np.argsort(post_syn[:,0])\n",
    "post_syn_sorted = post_syn[ind, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract synapse (pre-site) to synapse (post-site) connection\n",
    "# use only the post synaptic site to get all the synapses because one presynaptic site can have multiple postsynaptic sites\n",
    "post_syn_index = post_syn_sorted[:,0].copy()\n",
    "\n",
    "df = pd.read_csv('hemibrain_v1.0.1_neo4j_inputs/Neuprint_Synapse_Connections_52a133.csv')\n",
    "post_ids = df[':END_ID(Syn-ID)']\n",
    "used = np.where(post_ids.isin(post_syn_index).to_numpy())[0]\n",
    "connections = df.iloc[used].to_numpy()\n",
    "ind = np.argsort(connections[:,1])\n",
    "connections = connections[ind, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract synapse details\n",
    "chunksize = 100000\n",
    "\n",
    "pre_syn_index = list(set(pre_syn_sorted[:,0].copy()))\n",
    "pre_syn_index.extend(list(post_syn_sorted[:,0].copy()))\n",
    "syn_index = np.array(sorted(pre_syn_index))\n",
    "del pre_syn_index#, pre_syn_sorted, post_syn_sorted\n",
    "\n",
    "synapse_array = np.empty((len(syn_index), 230+6), np.int64)\n",
    "\n",
    "synapse_count = 0\n",
    "count = 0\n",
    "\n",
    "for chunk in pd.read_csv('hemibrain_v1.0.1_neo4j_inputs/Neuprint_Synapses_52a133.csv', chunksize=chunksize):\n",
    "    ids = chunk[':ID(Syn-ID)']\n",
    "    \n",
    "    start_id = ids.iloc[0]\n",
    "    stop_id = ids.iloc[-1]\n",
    "    pre_start = np.searchsorted(syn_index, start_id, side='left')\n",
    "    pre_end = np.searchsorted(syn_index, stop_id, side='right')\n",
    "    if pre_start >= len(syn_index):\n",
    "        pre_index = []\n",
    "    else:\n",
    "        if pre_end >= len(syn_index):\n",
    "            pre_index = syn_index[pre_start:pre_end] #same as syn_index[pre_start:]\n",
    "        else:\n",
    "            pre_index = syn_index[pre_start:pre_end]\n",
    "    pre_used_synapse = chunk.loc[ids.isin(pre_index)]\n",
    "    li = np.empty((pre_index.size, 230+6), np.int64)\n",
    "    i = 0\n",
    "    for _, row in pre_used_synapse.iterrows():\n",
    "        location = eval(row['location:point{srid:9157}'].replace('x', \"'x'\").replace('y', \"'y'\").replace('z', \"'z'\"))\n",
    "        li[i,:6] = [row[':ID(Syn-ID)'], # synpase id\n",
    "                     0 if row['type:string'] == 'pre' else 1, #synapse type\n",
    "                     int(row['confidence:float']*1000000), #confidence\n",
    "                     location['x'], location['y'], location['z']]\n",
    "        li[i,6:] = ~np.isnan(np.asarray(row.values[5:], np.double))\n",
    "        i += 1\n",
    "    synapse_array[synapse_count:synapse_count+pre_index.shape[0],:] = li\n",
    "    synapse_count += pre_index.shape[0]\n",
    "    count += chunksize\n",
    "    print(count, len(pre_used_synapse))\n",
    "synapse_array = synapse_array[:synapse_count,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder synapses\n",
    "\n",
    "synapse_connections = connections\n",
    "    \n",
    "ids = synapse_array[:,0]\n",
    "syn_id_dict = {j: i for i, j in enumerate(ids)}\n",
    "ids = post_syn_sorted[:,0]\n",
    "post_syn_id_dict = {j: i for i, j in enumerate(ids)} # map syn id to post_syn_sorted\n",
    "\n",
    "synapse_dict = {}\n",
    "wrong_synapse = 0\n",
    "for i, pair in tqdm(enumerate(synapse_connections)):\n",
    "    pre_syn_id = pair[0]\n",
    "    post_syn_id = pair[1]\n",
    "    post_id = post_syn_id_dict[post_syn_id]\n",
    "    post_info = synapse_array[syn_id_dict[post_syn_id]]\n",
    "    post_neuron_id, pre_neuron_id = post_syn_sorted[post_id, 1:]\n",
    "\n",
    "    pre_info = synapse_array[syn_id_dict[pre_syn_id]]\n",
    "\n",
    "    if pre_neuron_id not in synapse_dict:\n",
    "        synapse_dict[pre_neuron_id] = {}\n",
    "    pre_dict = synapse_dict[pre_neuron_id]\n",
    "    if post_neuron_id not in synapse_dict[pre_neuron_id]:\n",
    "        pre_dict[post_neuron_id] =  {'pre_synapse_ids': [],\n",
    "                                     'post_synapse_ids': [],\n",
    "                                     'pre_confidence': [],\n",
    "                                     'post_confidence': [],\n",
    "                                     'pre_x': [],\n",
    "                                     'pre_y': [],\n",
    "                                     'pre_z': [],\n",
    "                                     'post_x': [],\n",
    "                                     'post_y': [],\n",
    "                                     'post_z': [],\n",
    "                                     'regions': np.zeros(230, np.int32)}\n",
    "    info_dict = pre_dict[post_neuron_id]\n",
    "    info_dict['pre_synapse_ids'].append(pre_syn_id)\n",
    "    info_dict['post_synapse_ids'].append(post_syn_id)\n",
    "    info_dict['pre_confidence'].append(pre_info[2])\n",
    "    info_dict['post_confidence'].append(post_info[2])\n",
    "    info_dict['pre_x'].append(pre_info[3])\n",
    "    info_dict['pre_y'].append(pre_info[4])\n",
    "    info_dict['pre_z'].append(pre_info[5])\n",
    "    info_dict['post_x'].append(post_info[3])\n",
    "    info_dict['post_y'].append(post_info[4])\n",
    "    info_dict['post_z'].append(post_info[5])\n",
    "    info_dict['regions'] += post_info[6:]\n",
    "\n",
    "chunk = pd.read_csv('hemibrain_v1.0.1_neo4j_inputs/Neuprint_Synapses_52a133.csv', chunksize=1).get_chunk()\n",
    "labels = [i.split(':')[0] for i in chunk.columns.to_list()]\n",
    "regions = labels[5:]\n",
    "\n",
    "with open('synapses.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['pre_id','post_id','N','pre_confidence','post_confidence',\\\n",
    "                     'pre_x','pre_y','pre_z','post_x','post_y','post_z',\\\n",
    "                     'neuropils','subregions','tracts'])\n",
    "    for pre, k in tqdm(synapse_dict.items()):\n",
    "        for post, v in k.items():\n",
    "            reg = {regions[i]: v['regions'][i] for i in np.nonzero(v['regions'])[0]}\n",
    "            neuropil_list = []\n",
    "            subregion_list = []\n",
    "            tract_list = []\n",
    "            for k, n in reg.items():\n",
    "                region = all_brain_regions[k]\n",
    "                if region['Subregions'] is None:\n",
    "                    if region['Neuropil'] is None:\n",
    "                        if 'Tract' in region:\n",
    "                            tract_list.append('{}:{}'.format(\n",
    "                                region['Tract'], n))\n",
    "                        else:\n",
    "                            continue\n",
    "                    elif isinstance(region['Neuropil'], list):\n",
    "                        continue\n",
    "                    else:\n",
    "                        neuropil_list.append('{}:{}'.format(\n",
    "                            region['Neuropil'], n))\n",
    "                else:\n",
    "                    subregion_list.append('{}:{}'.format(\n",
    "                        region['Subregions'], n))\n",
    "\n",
    "            neuropil_list = ';'.join(neuropil_list)\n",
    "            subregion_list = ';'.join(subregion_list)\n",
    "            tract_list = ';'.join(tract_list)\n",
    "            writer.writerow([pre, post, len(v['pre_x']), str(v['pre_confidence']), \\\n",
    "                             str(v['post_confidence']), str(v['pre_x']), str(v['pre_y']), str(v['pre_z']), \\\n",
    "                             str(v['post_x']), str(v['post_y']), str(v['post_z']), \\\n",
    "                             neuropil_list, subregion_list, tract_list])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading NeuroArch Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and connect to database. mode 'o' overwrites the entire database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemibrain = na.NeuroArch('hemibrain', mode = 'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species = hemibrain.add_species('Drosophila melanogaster', stage = 'adult',\n",
    "                                sex = 'female',\n",
    "                                synonyms = ['fruit fly', 'common fruit fly', 'vinegar fly'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a datasource under the species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = '1.0.1'\n",
    "datasource = hemibrain.add_DataSource('Hemibrain', version = version,\n",
    "                                      url = 'https://www.janelia.org/project-team/flyem/hemibrain',\n",
    "                                      species = species)\n",
    "hemibrain.default_DataSource = datasource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create subsystems, tracts, neuropils and subregions under the datasource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in all_brain_regions.items():\n",
    "    if v['Neuropil'] is None and v['Subregions'] is None:\n",
    "        if 'System' in v:\n",
    "            hemibrain.add_Subsystem(k)\n",
    "    elif 'System' in v:\n",
    "        if v['Neuropil'] == v['System'] and v['Subregions'] is None:\n",
    "            hemibrain.add_Subsystem(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mesh are then downsampled using [MeshLab](https://www.meshlab.net/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('filter_file_tmp.mlx', 'w') as f:\n",
    "    f.write(\"\"\"<!DOCTYPE FilterScript>\n",
    "<FilterScript>\n",
    " <filter name=\"Simplification: Quadric Edge Collapse Decimation\">\n",
    "  <Param type=\"RichInt\" value=\"60000\" name=\"TargetFaceNum\"/>\n",
    "  <Param type=\"RichFloat\" value=\"0.05\" name=\"TargetPerc\"/>\n",
    "  <Param type=\"RichFloat\" value=\"1\" name=\"QualityThr\"/>\n",
    "  <Param type=\"RichBool\" value=\"true\" name=\"PreserveBoundary\"/>\n",
    "  <Param type=\"RichFloat\" value=\"1\" name=\"BoundaryWeight\"/>\n",
    "  <Param type=\"RichBool\" value=\"true\" name=\"OptimalPlacement\"/>\n",
    "  <Param type=\"RichBool\" value=\"true\" name=\"PreserveNormal\"/>\n",
    "  <Param type=\"RichBool\" value=\"true\" name=\"PlanarSimplification\"/>\n",
    " </filter>\n",
    "</FilterScript>\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in all_brain_regions.items():\n",
    "    if v['Neuropil'] is None and v['Subregions'] is None:\n",
    "        if 'Tract' in v:\n",
    "            ms = ml.MeshSet()\n",
    "            ms.load_new_mesh(\"roi/{}.obj\".format(k))\n",
    "            ms.load_filter_script('filter_file_tmp.mlx')\n",
    "            ms.apply_filter_script()\n",
    "            current_mesh = ms.current_mesh()\n",
    "            hemibrain.add_Tract(k, morphology = {'type': 'mesh', \n",
    "                                                 \"vertices\": (current_mesh.vertex_matrix()*0.008).flatten().tolist(),\n",
    "                                                 \"faces\": current_mesh.face_matrix().flatten().tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in all_brain_regions.items():\n",
    "    if v['Neuropil'] is not None and v['Subregions'] is None:\n",
    "        if isinstance(v['Neuropil'], list):\n",
    "            continue\n",
    "        ms = ml.MeshSet()\n",
    "        ms.load_new_mesh(\"roi/{}.obj\".format(k))\n",
    "        ms.load_filter_script('filter_file_tmp.mlx')\n",
    "        ms.apply_filter_script()\n",
    "        current_mesh = ms.current_mesh()\n",
    "        hemibrain.add_Neuropil(k,\n",
    "                               morphology = {'type': 'mesh', \n",
    "                                             \"vertices\": (current_mesh.vertex_matrix()*0.008).flatten().tolist(),\n",
    "                                             \"faces\": current_mesh.face_matrix().flatten().tolist()},\n",
    "                               subsystem = v['System'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in all_brain_regions.items():\n",
    "    if v['Subregions'] is not None:\n",
    "        if isinstance(v['Neuropil'], list):\n",
    "            continue\n",
    "        if os.path.exists(\"roi/{}.obj\".format(k)):\n",
    "            ms = ml.MeshSet()\n",
    "            ms.load_new_mesh(\"roi/{}.obj\".format(k))\n",
    "            ms.load_filter_script('filter_file_tmp.mlx')\n",
    "            ms.apply_filter_script()\n",
    "            current_mesh = ms.current_mesh()\n",
    "            hemibrain.add_Subregion(k,\n",
    "                                    morphology = {'type': 'mesh', \n",
    "                                                  \"vertices\": (current_mesh.vertex_matrix()*0.008).flatten().tolist(),\n",
    "                                                  \"faces\": current_mesh.face_matrix().flatten().tolist()},\n",
    "                                    neuropil = v['Neuropil'])\n",
    "        else:\n",
    "            hemibrain.add_Subregion(k,\n",
    "                                    neuropil = v['Neuropil'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_swc(file_name):\n",
    "    df = pd.read_csv(file_name, sep = ' ', header = None, comment = '#', index_col = False,\n",
    "                     names = ['sample', 'x', 'y', 'z', 'r', 'parent'],\n",
    "                    skipinitialspace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_list = pd.read_csv('neurons.csv')\n",
    "swc_dir = 'swc'\n",
    "uname_dict = {}\n",
    "\n",
    "for i, row in tqdm(neuron_list.iterrows()):\n",
    "    if row['statusLabel'] in ['Traced', 'Roughly traced']:\n",
    "        pass\n",
    "    elif isinstance(row['instance'], str) or  isinstance(row['type'], str):\n",
    "        pass\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    bodyID = row['bodyID']\n",
    "    cell_type = row['type']\n",
    "    name = row['instance']\n",
    "    \n",
    "    if not isinstance(name, str):\n",
    "        if isinstance(cell_type, str):\n",
    "            name = '{}_{}'.format(cell_type, bodyID)\n",
    "        else:\n",
    "            cell_type = 'unknown'\n",
    "            name = 'unknown_{}'.format(bodyID)\n",
    "    else:\n",
    "        if not isinstance(cell_type, str):\n",
    "            cell_type = 'unknown'\n",
    "            if not isinstance(name, str):\n",
    "                name = 'unknown_{}'.format(bodyID)\n",
    "            else:\n",
    "                name = '{}_{}'.format(name, bodyID)\n",
    "        else:\n",
    "            if name not in uname_dict:\n",
    "                uname_dict[name] = 0\n",
    "            uname_dict[name] += 1\n",
    "            name = '{}_{}'.format(name, uname_dict[name])\n",
    "                \n",
    "    info = {}\n",
    "    \n",
    "    c_neuropils = row['neuropils']\n",
    "    c_subregions = row['subregions']\n",
    "    c_tracts = row['tracts']\n",
    "    arborization = []\n",
    "    if isinstance(c_neuropils, str):\n",
    "        dendrites = {j.split(':')[0]: int(j.split(':')[2]) for j in c_neuropils.split(';') if int(j.split(':')[2]) > 0}\n",
    "        axons = {j.split(':')[0]: int(j.split(':')[1]) for j in c_neuropils.split(';') if int(j.split(':')[1]) > 0}\n",
    "        arborization.append({'dendrites': dendrites, 'axons': axons, 'type': 'neuropil'})\n",
    "    if isinstance(c_subregions, str):\n",
    "        dendrites = {j.split(':')[0]: int(j.split(':')[2]) for j in c_subregions.split(';') if int(j.split(':')[2]) > 0}\n",
    "        axons = {j.split(':')[0]: int(j.split(':')[1]) for j in c_subregions.split(';') if int(j.split(':')[1]) > 0}\n",
    "        arborization.append({'dendrites': dendrites, 'axons': axons, 'type': 'subregion'})\n",
    "    if isinstance(c_tracts, str):\n",
    "        dendrites = {j.split(':')[0]: int(j.split(':')[2]) for j in c_tracts.split(';') if int(j.split(':')[2]) > 0}\n",
    "        axons = {j.split(':')[0]: int(j.split(':')[1]) for j in c_tracts.split(';') if int(j.split(':')[1]) > 0}\n",
    "        arborization.append({'dendrites': dendrites, 'axons': axons, 'type': 'tract'})\n",
    "    \n",
    "    df = load_swc('{}/{}.swc'.format(swc_dir, bodyID))\n",
    "    morphology = {'x': (df['x']*0.008).tolist(),\n",
    "                  'y': (df['y']*0.008).tolist(),\n",
    "                  'z': (df['z']*0.008).tolist(),\n",
    "                  'r': (df['r']*0.008).tolist(),\n",
    "                  'parent': df['parent'].tolist(),\n",
    "                  'identifier': [0]*(len(df['x'])),\n",
    "                  'sample': df['sample'].tolist(),\n",
    "                  'type': 'swc'}\n",
    "    \n",
    "    hemibrain.add_Neuron(name, # uname\n",
    "                         cell_type, # name\n",
    "                         referenceId = str(bodyID), #referenceId\n",
    "                         info = info if len(info) else None,\n",
    "                         morphology = morphology,\n",
    "                         arborization = arborization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If restarting the kernel after loading neurons, start with this\n",
    "# hemibrain = na.NeuroArch('hemibrain', mode = 'w')\n",
    "# hemibrain.default_DataSource = hemibrain.find_objs('DataSource', name = 'Hemibrain')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all the neurons so they can be keyed by their referenceId.\n",
    "\n",
    "neurons = hemibrain.sql_query('select from Neuron').nodes_as_objs\n",
    "# set the cache so there is no need for database access.\n",
    "for neuron in neurons:\n",
    "    hemibrain.set('Neuron', neuron.uname, neuron, hemibrain.default_DataSource)\n",
    "neuron_ref_to_obj = {int(neuron.referenceId): neuron for neuron in neurons}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load synapses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synapse_df = pd.read_csv('synapses.csv')\n",
    "\n",
    "for i, row in tqdm(synapse_df.iterrows()):\n",
    "    pre_neuron = neuron_ref_to_obj[row['pre_id']]\n",
    "    post_neuron = neuron_ref_to_obj[row['post_id']]\n",
    "\n",
    "    pre_conf = np.array(eval(row['pre_confidence']))/1e6\n",
    "    post_conf = np.array(eval(row['post_confidence']))/1e6\n",
    "    NHP = np.sum(np.logical_and(post_conf>=0.7, pre_conf>=0.7))\n",
    "\n",
    "    c_neuropils = row['neuropils']\n",
    "    c_subregions = row['subregions']\n",
    "    c_tracts = row['tracts']\n",
    "    arborization = []\n",
    "    neuropils = {}\n",
    "    if isinstance(c_neuropils, str):\n",
    "        arborization.append({'type': 'neuropil',\n",
    "                       'synapses': {j.split(':')[0]: int(j.split(':')[1]) \\\n",
    "                                    for j in c_neuropils.split(';') \\\n",
    "                                    if int(j.split(':')[1]) > 0}})\n",
    "    if isinstance(c_subregions, str):\n",
    "        arborization.append({'type': 'subregion',\n",
    "                             'synapses': {j.split(':')[0]: int(j.split(':')[1]) \\\n",
    "                                          for j in c_subregions.split(';') \\\n",
    "                                          if int(j.split(':')[1]) > 0}})\n",
    "    if isinstance(c_tracts, str):\n",
    "        arborization.append({'type': 'tract',\n",
    "                             'synapses': {j.split(':')[0]: int(j.split(':')[1]) \\\n",
    "                                          for j in c_tracts.split(';') \\\n",
    "                                          if int(j.split(':')[1]) > 0}})\n",
    "    content = {'type': 'swc'}\n",
    "    content['x'] = [round(i, 3) for i in (np.array(eval(row['pre_x'])+eval(row['post_x']))*0.008).tolist()]\n",
    "    content['y'] = [round(i, 3) for i in (np.array(eval(row['pre_y'])+eval(row['post_y']))*0.008).tolist()]\n",
    "    content['z'] = [round(i, 3) for i in (np.array(eval(row['pre_z'])+eval(row['post_z']))*0.008).tolist()]\n",
    "    content['r'] = [0]*len(content['x'])\n",
    "    content['parent'] = [-1]*(len(content['x'])//2) + [i+1 for i in range(len(content['x'])//2)]\n",
    "    content['identifier'] = [7]*(len(content['x'])//2) + [8]*(len(content['x'])//2)\n",
    "    content['sample'] = [i+1 for i in range(len(content['x']))]\n",
    "    content['confidence'] = [round(i, 3) for i in pre_conf.tolist()] + [round(i, 3) for i in post_conf.tolist()]\n",
    "    \n",
    "    hemibrain.add_Synapse(pre_neuron, post_neuron, N = row['N'], NHP = NHP,\n",
    "                          morphology = content,\n",
    "                          arborization = arborization)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
