{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading NeuroArch Database with Hemibrain Dataset Release 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial provides code to load NeuroArch database with Hemibrain Dataset v1.2. Requirement before running the notebook:\n",
    "- Installed [NeuroArch](https://github.com/fruitflybrain/neuroarch), [OrientDB Community Version](https://www.orientdb.org/download), and [pyorient](https://github.com/fruitflybrain/pyorient). The [NeuroNLP Docker image](https://hub.docker.com/r/fruitflybrain/neuronlp) and [FlyBrainLab Docker image](https://hub.docker.com/r/fruitflybrain/fbl) all have a copy of the software requirement ready.\n",
    "- Installed [PyMeshLab](https://pypi.org/project/pymeshlab/).\n",
    "- Installed [neuprint-python](https://github.com/connectome-neuprint/neuprint-python).\n",
    "- Download the [Neuprint database dump for the Hemibrain dataset v1.2](https://storage.cloud.google.com/hemibrain-release/neuprint/hemibrain_v1.2_neo4j_inputs.zip).\n",
    "- Have the [token](https://connectome-neuprint.github.io/neuprint-python/docs/client.html#neuprint.client.Client) for Neuprint HTTP access ready.\n",
    "- Have more than 60 GB free disk space (for Neuprint dump and NeuroArch database).\n",
    "\n",
    "A backup of the database created by this notebook can be downloaded [here](https://drive.google.com/file/d/1UguZ-9kuHVZF5_yZzlpyRAGVGrx41NHv/view?usp=sharing). To restore it in OrientDB, run\n",
    "```\n",
    "/path/to/orientdb/bin/console.sh \"create database plocal:../databases/hemibrain admin admin; restore database /path/to/hemibrain1.2_na_v1.0_backup.zip\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import subprocess\n",
    "import csv\n",
    "import json\n",
    "import warnings\n",
    "from requests import HTTPError\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from neuprint import Client\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import pymeshlab as ml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Brain Region\n",
    "First define all brain regions in the hemibrain data, and assign them as subsystem, neuropil or subregions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_brain_regions = \\\n",
    "{'OL(R)': {'System': 'OL(R)', 'Neuropil': None, 'Subregions': None},\n",
    "'MB(R)': {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': None},\n",
    "'MB(L)': {'System': 'MB(+ACA)(L)', 'Neuropil': 'MB(L)', 'Subregions': None},\n",
    "'CX': {'System': 'CX', 'Neuropil': None, 'Subregions': None},\n",
    "'LX(R)': {'System': 'LX(R)', 'Neuropil': None, 'Subregions': None},\n",
    "'LX(L)': {'System': 'LX(L)', 'Neuropil': None, 'Subregions': None},\n",
    "'VLNP(R)': {'System': 'VLNP(R)', 'Neuropil': None, 'Subregions': None},\n",
    "'LH(R)': {'System': 'LH(R)', 'Neuropil': 'LH(R)', 'Subregions': None},\n",
    "'SNP(R)': {'System': 'SNP(R)', 'Neuropil': None, 'Subregions': None},\n",
    "'SNP(L)': {'System': 'SNP(L)', 'Neuropil': None, 'Subregions': None},\n",
    "'INP': {'System': 'INP', 'Neuropil': None, 'Subregions': None},\n",
    "'AL(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': None},\n",
    "'AL(L)': {'System': 'AL(L)', 'Neuropil': 'AL(L)', 'Subregions': None},\n",
    "'VMNP': {'System': 'VMNP', 'Neuropil': None, 'Subregions': None},\n",
    "'PENP': {'System': 'PENP', 'Neuropil': None, 'Subregions': None},\n",
    "'GNG': {'System': 'GNG', 'Neuropil': 'GNG', 'Subregions': None},\n",
    "'AOT(R)': {'Tract': 'AOT(R)', 'Neuropil': None, 'Subregions': None},\n",
    "'GC': {'Tract': 'GC', 'Neuropil': None, 'Subregions': None},\n",
    "'GF(R)': {'Tract': 'GF(R)', 'Neuropil': None, 'Subregions': None},\n",
    "'mALT(R)': {'Tract': 'mALT(R)', 'Neuropil': None, 'Subregions': None},\n",
    "'mALT(L)': {'Tract': 'mALT(L)', 'Neuropil': None, 'Subregions': None},\n",
    "'POC': {'Tract': 'POC', 'Neuropil': None, 'Subregions': None},\n",
    "'ME(R)': {'System': 'OL(R)', 'Neuropil': 'ME(R)', 'Subregions': None},\n",
    "'AME(R)': {'System': 'OL(R)', 'Neuropil': 'AME(R)', 'Subregions': None},\n",
    "'CA(R)': {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': 'CA(R)'},\n",
    "'CA(L)': {'System': 'MB(+ACA)(L)', 'Neuropil': 'MB(L)', 'Subregions': 'CA(L)'},\n",
    "'dACA(R)': {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': 'dACA(R)'},\n",
    "'lACA(R)': {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': 'lACA(R)'},\n",
    "'vACA(R)': {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': 'vACA(R)'},\n",
    "'PED(R)': {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': 'PED(R)'},\n",
    "'CB': {'System': 'CX', 'Neuropil': ['FB', 'EB'], 'Subregions': None},\n",
    "'PB': {'System': 'CX', 'Neuropil': 'PB', 'Subregions': None},\n",
    "'NO': {'System': 'CX', 'Neuropil': ['NO(R)', 'NO(L)'], 'Subregions': None},\n",
    "'BU(R)': {'System': 'LX(R)', 'Neuropil': 'BU(R)', 'Subregions': None},\n",
    "'BU(L)': {'System': 'LX(L)', 'Neuropil': 'BU(L)', 'Subregions': None},\n",
    "'LAL(R)': {'System': 'LX(R)', 'Neuropil': 'LAL(R)', 'Subregions': None},\n",
    "'LAL(L)': {'System': 'LX(L)', 'Neuropil': 'LAL(L)', 'Subregions': None},\n",
    "'AOTU(R)': {'System': 'VLNP(R)', 'Neuropil': 'AOTU(R)', 'Subregions': None},\n",
    "'PLP(R)': {'System': 'VLNP(R)', 'Neuropil': 'PLP(R)', 'Subregions': None},\n",
    "'WED(R)': {'System': 'VLNP(R)', 'Neuropil': 'WED(R)', 'Subregions': None},\n",
    "'SLP(R)': {'System': 'SNP(R)', 'Neuropil': 'SLP(R)', 'Subregions': None},\n",
    "'SIP(R)': {'System': 'SNP(R)', 'Neuropil': 'SIP(R)', 'Subregions': None},\n",
    "'SIP(L)': {'System': 'SNP(L)', 'Neuropil': 'SIP(L)', 'Subregions': None},\n",
    "'SMP(R)': {'System': 'SNP(R)', 'Neuropil': 'SMP(R)', 'Subregions': None},\n",
    "'SMP(L)': {'System': 'SNP(L)', 'Neuropil': 'SMP(L)', 'Subregions': None},\n",
    "'CRE(R)': {'System': 'INP', 'Neuropil': 'CRE(R)', 'Subregions': None},\n",
    "'CRE(L)': {'System': 'INP', 'Neuropil': 'CRE(L)', 'Subregions': None},\n",
    "'IB': {'System': 'INP', 'Neuropil': 'IB', 'Subregions': None},\n",
    "'ATL(R)': {'System': 'INP', 'Neuropil': 'ATL(R)', 'Subregions': None},\n",
    "'ATL(L)': {'System': 'INP', 'Neuropil': 'ATL(L)', 'Subregions': None},\n",
    "'SAD': {'System': 'PENP', 'Neuropil': 'SAD', 'Subregions': None},\n",
    "'FLA(R)': {'System': 'PENP', 'Neuropil': 'FLA(R)', 'Subregions': None},\n",
    "'CAN(R)': {'System': 'PENP', 'Neuropil': 'CAN(R)', 'Subregions': None},\n",
    "'PRW': {'System': 'PENP', 'Neuropil': 'PRW', 'Subregions': None},\n",
    "'LO(R)': {'System': 'OL(R)', 'Neuropil': 'LO(R)', 'Subregions': None},\n",
    "'LOP(R)': {'System': 'OL(R)', 'Neuropil': 'LOP(R)', 'Subregions': None},\n",
    "\"a'L(R)\": {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': \"a'L(R)\"},\n",
    "\"a'1(R)\": {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': \"a'1(R)\"},\n",
    "\"a'2(R)\": {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': \"a'2(R)\"},\n",
    "\"a'3(R)\": {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': \"a'3(R)\"},\n",
    "\"a'L(L)\": {'System': 'MB(+ACA)(L)', 'Neuropil': 'MB(L)', 'Subregions': \"a'L(L)\"},\n",
    "'aL(R)': {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': 'aL(R)'},\n",
    "'a1(R)': {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': 'a1(R)'},\n",
    "'a2(R)': {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': 'a2(R)'},\n",
    "'a3(R)': {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': 'a3(R)'},\n",
    "'aL(L)': {'System': 'MB(+ACA)(L)', 'Neuropil': 'MB(L)', 'Subregions': 'aL(L)'},\n",
    "'gL(R)': {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': 'gL(R)'},\n",
    "'g1(R)': {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': 'g1(R)'},\n",
    "'g2(R)': {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': 'g2(R)'},\n",
    "'g3(R)': {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': 'g3(R)'},\n",
    "'g4(R)': {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': 'g4(R)'},\n",
    "'g5(R)': {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': 'g5(R)'},\n",
    "'gL(L)': {'System': 'MB(+ACA)(L)', 'Neuropil': 'MB(L)', 'Subregions': 'gL(L)'},\n",
    "\"b'L(R)\": {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': \"b'L(R)\"},\n",
    "\"b'1(R)\": {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': \"b'1(R)\"},\n",
    "\"b'2(R)\": {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': \"b'2(R)\"},\n",
    "\"b'L(L)\": {'System': 'MB(+ACA)(L)', 'Neuropil': 'MB(L)', 'Subregions': \"b'L(L)\"},\n",
    "'bL(R)': {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': 'bL(R)'},\n",
    "'b1(R)': {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': 'b1(R)'},\n",
    "'b2(R)': {'System': 'MB(+ACA)(R)', 'Neuropil': 'MB(R)', 'Subregions': 'b2(R)'},\n",
    "'bL(L)': {'System': 'MB(+ACA)(L)', 'Neuropil': 'MB(L)', 'Subregions': 'bL(L)'},\n",
    "'FB': {'System': 'CX', 'Neuropil': 'FB', 'Subregions': None},\n",
    "'FBl1': {'System': 'CX', 'Neuropil': 'FB', 'Subregions': 'FBl1'},\n",
    "'FBl2': {'System': 'CX', 'Neuropil': 'FB', 'Subregions': 'FBl2'},\n",
    "'FBl3': {'System': 'CX', 'Neuropil': 'FB', 'Subregions': 'FBl3'},\n",
    "'FBl4': {'System': 'CX', 'Neuropil': 'FB', 'Subregions': 'FBl4'},\n",
    "'FBl5': {'System': 'CX', 'Neuropil': 'FB', 'Subregions': 'FBl5'},\n",
    "'FBl6': {'System': 'CX', 'Neuropil': 'FB', 'Subregions': 'FBl6'},\n",
    "'FBl7': {'System': 'CX', 'Neuropil': 'FB', 'Subregions': 'FBl7'},\n",
    "'FBl8': {'System': 'CX', 'Neuropil': 'FB', 'Subregions': 'FBl8'},\n",
    "'FBl9': {'System': 'CX', 'Neuropil': 'FB', 'Subregions': 'FBl9'},\n",
    "'EB': {'System': 'CX', 'Neuropil': 'EB', 'Subregions': None},\n",
    "'EBr1': {'System': 'CX', 'Neuropil': 'EB', 'Subregions': 'EBr1'},\n",
    "'EBr2r4': {'System': 'CX', 'Neuropil': 'EB', 'Subregions': 'EBr2r4'},\n",
    "'EBr3am': {'System': 'CX', 'Neuropil': 'EB', 'Subregions': 'EBr3am'},\n",
    "'EBr3d': {'System': 'CX', 'Neuropil': 'EB', 'Subregions': 'EBr3d'},\n",
    "'EBr3pw': {'System': 'CX', 'Neuropil': 'EB', 'Subregions': 'EBr3pw'},\n",
    "'EBr5': {'System': 'CX', 'Neuropil': 'EB', 'Subregions': 'EBr5'},\n",
    "'EBr6': {'System': 'CX', 'Neuropil': 'EB', 'Subregions': 'EBr6'},\n",
    "'PB(R1)': {'System': 'CX', 'Neuropil': 'PB', 'Subregions': 'PB(R1)'},\n",
    "'PB(R2)': {'System': 'CX', 'Neuropil': 'PB', 'Subregions': 'PB(R2)'},\n",
    "'PB(R3)': {'System': 'CX', 'Neuropil': 'PB', 'Subregions': 'PB(R3)'},\n",
    "'PB(R4)': {'System': 'CX', 'Neuropil': 'PB', 'Subregions': 'PB(R4)'},\n",
    "'PB(R5)': {'System': 'CX', 'Neuropil': 'PB', 'Subregions': 'PB(R5)'},\n",
    "'PB(R6)': {'System': 'CX', 'Neuropil': 'PB', 'Subregions': 'PB(R6)'},\n",
    "'PB(R7)': {'System': 'CX', 'Neuropil': 'PB', 'Subregions': 'PB(R7)'},\n",
    "'PB(R8)': {'System': 'CX', 'Neuropil': 'PB', 'Subregions': 'PB(R8)'},\n",
    "'PB(R9)': {'System': 'CX', 'Neuropil': 'PB', 'Subregions': 'PB(R9)'},\n",
    "'PB(L1)': {'System': 'CX', 'Neuropil': 'PB', 'Subregions': 'PB(L1)'},\n",
    "'PB(L2)': {'System': 'CX', 'Neuropil': 'PB', 'Subregions': 'PB(L2)'},\n",
    "'PB(L3)': {'System': 'CX', 'Neuropil': 'PB', 'Subregions': 'PB(L3)'},\n",
    "'PB(L4)': {'System': 'CX', 'Neuropil': 'PB', 'Subregions': 'PB(L4)'},\n",
    "'PB(L5)': {'System': 'CX', 'Neuropil': 'PB', 'Subregions': 'PB(L5)'},\n",
    "'PB(L6)': {'System': 'CX', 'Neuropil': 'PB', 'Subregions': 'PB(L6)'},\n",
    "'PB(L7)': {'System': 'CX', 'Neuropil': 'PB', 'Subregions': 'PB(L7)'},\n",
    "'PB(L8)': {'System': 'CX', 'Neuropil': 'PB', 'Subregions': 'PB(L8)'},\n",
    "'PB(L9)': {'System': 'CX', 'Neuropil': 'PB', 'Subregions': 'PB(L9)'},\n",
    "'NO(R)': {'System': 'CX', 'Neuropil': 'NO(R)', 'Subregions': None},\n",
    "'NO(L)': {'System': 'CX', 'Neuropil': 'NO(L)', 'Subregions': None},\n",
    "'GA(R)': {'System': 'LX(R)', 'Neuropil': 'LAL(R)', 'Subregions': 'GA(R)'},\n",
    "'AVLP(R)': {'System': 'VLNP(R)', 'Neuropil': 'AVLP(R)', 'Subregions': None},\n",
    "'PVLP(R)': {'System': 'VLNP(R)', 'Neuropil': 'PVLP(R)', 'Subregions': None},\n",
    "'RUB(R)': {'System': 'INP', 'Neuropil': 'CRE(R)', 'Subregions': 'RUB(R)'},\n",
    "'RUB(L)': {'System': 'INP', 'Neuropil': 'CRE(L)', 'Subregions': 'RUB(L)'},\n",
    "'ROB(R)': {'System': 'INP', 'Neuropil': 'CRE(R)', 'Subregions': 'ROB(R)'},\n",
    "'SCL(R)': {'System': 'INP', 'Neuropil': 'SCL(R)', 'Subregions': None},\n",
    "'SCL(L)': {'System': 'INP', 'Neuropil': 'SCL(L)', 'Subregions': None},\n",
    "'ICL(R)': {'System': 'INP', 'Neuropil': 'ICL(R)', 'Subregions': None},\n",
    "'ICL(L)': {'System': 'INP', 'Neuropil': 'ICL(L)', 'Subregions': None},\n",
    "'VES(R)': {'System': 'VMNP', 'Neuropil': 'VES(R)', 'Subregions': None},\n",
    "'VES(L)': {'System': 'VMNP', 'Neuropil': 'VES(L)', 'Subregions': None},\n",
    "'EPA(R)': {'System': 'VMNP', 'Neuropil': 'EPA(R)', 'Subregions': None},\n",
    "'EPA(L)': {'System': 'VMNP', 'Neuropil': 'EPA(L)', 'Subregions': None},\n",
    "'GOR(R)': {'System': 'VMNP', 'Neuropil': 'GOR(R)', 'Subregions': None},\n",
    "'GOR(L)': {'System': 'VMNP', 'Neuropil': 'GOR(L)', 'Subregions': None},\n",
    "'SPS(R)': {'System': 'VMNP', 'Neuropil': 'SPS(R)', 'Subregions': None},\n",
    "'SPS(L)': {'System': 'VMNP', 'Neuropil': 'SPS(L)', 'Subregions': None},\n",
    "'IPS(R)': {'System': 'VMNP', 'Neuropil': 'IPS(R)', 'Subregions': None},\n",
    "'AMMC': {'System': 'PENP', 'Neuropil': 'SAD', 'Subregions': 'AMMC'},\n",
    "'AB(R)': {'System': 'CX', 'Neuropil': 'AB(R)', 'Subregions': None},\n",
    "'AB(L)': {'System': 'CX', 'Neuropil': 'AB(L)', 'Subregions': None},\n",
    "'FB-column3': {'System': 'CX', 'Neuropil': 'FB', 'Subregions': 'FB-column3'},\n",
    "'NO1(R)': {'System': 'CX', 'Neuropil': 'NO(R)', 'Subregions': 'NO1(R)'},\n",
    "'NO1(L)': {'System': 'CX', 'Neuropil': 'NO(L)', 'Subregions': 'NO1(L)'},\n",
    "'NO2(R)': {'System': 'CX', 'Neuropil': 'NO(R)', 'Subregions': 'NO2(R)'},\n",
    "'NO2(L)': {'System': 'CX', 'Neuropil': 'NO(L)', 'Subregions': 'NO2(L)'},\n",
    "'NO3(R)': {'System': 'CX', 'Neuropil': 'NO(R)', 'Subregions': 'NO3(R)'},\n",
    "'NO3(L)': {'System': 'CX', 'Neuropil': 'NO(L)', 'Subregions': 'NO3(L)'},\n",
    "'MB(+ACA)(R)': {'System': 'MB(+ACA)(R)', 'Neuropil': None, 'Subregions': None},\n",
    "'MB(+ACA)(L)': {'System': 'MB(+ACA)(L)', 'Neuropil': None, 'Subregions': None},\n",
    "'LAL(-GA)(R)': {'System': 'LX(R)', 'Neuropil': 'LAL(R)', 'Subregions': 'LAL(-GA)(R)'},\n",
    "'SAD(-AMMC)': {'System': 'PENP', 'Neuropil': 'SAD', 'Subregions': 'SAD(-AMMC)'},\n",
    "'CRE(-RUB)(L)': {'System': 'INP', 'Neuropil': 'CRE(L)', 'Subregions': 'CRE(-RUB)(L)'},\n",
    "'CRE(-ROB,-RUB)(R)': {'System': 'INP', 'Neuropil': 'CRE(R)', 'Subregions': 'CRE(-ROB,-RUB)(R)'},\n",
    "'AL-DA1(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-DA1(R)'},\n",
    "'AL-DA2(L)': {'System': 'AL(L)', 'Neuropil': 'AL(L)', 'Subregions': 'AL-DA2(L)'},\n",
    "'AL-DA2(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-DA2(R)'},\n",
    "'AL-DA3(L)': {'System': 'AL(L)', 'Neuropil': 'AL(L)', 'Subregions': 'AL-DA3(L)'},\n",
    "'AL-DA3(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-DA3(R)'},\n",
    "'AL-DA4l(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-DA4l(R)'},\n",
    "'AL-DA4m(L)': {'System': 'AL(L)', 'Neuropil': 'AL(L)', 'Subregions': 'AL-DA4m(L)'},\n",
    "'AL-DA4m(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-DA4m(R)'},\n",
    "'AL-DC1(L)': {'System': 'AL(L)', 'Neuropil': 'AL(L)', 'Subregions': 'AL-DC1(L)'},\n",
    "'AL-DC1(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-DC1(R)'},\n",
    "'AL-DC2(L)': {'System': 'AL(L)', 'Neuropil': 'AL(L)', 'Subregions': 'AL-DC2(L)'},\n",
    "'AL-DC2(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-DC2(R)'},\n",
    "'AL-DC3(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-DC3(R)'},\n",
    "'AL-DC4(L)': {'System': 'AL(L)', 'Neuropil': 'AL(L)', 'Subregions': 'AL-DC4(L)'},\n",
    "'AL-DC4(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-DC4(R)'},\n",
    "'AL-DL1(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-DL1(R)'},\n",
    "'AL-DL2d(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-DL2d(R)'},\n",
    "'AL-DL2v(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-DL2v(R)'},\n",
    "'AL-DL3(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-DL3(R)'},\n",
    "'AL-DL4(L)': {'System': 'AL(L)', 'Neuropil': 'AL(L)', 'Subregions': 'AL-DL4(L)'},\n",
    "'AL-DL4(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-DL4(R)'},\n",
    "'AL-DL5(L)': {'System': 'AL(L)', 'Neuropil': 'AL(L)', 'Subregions': 'AL-DL5(L)'},\n",
    "'AL-DL5(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-DL5(R)'},\n",
    "'AL-D(L)': {'System': 'AL(L)', 'Neuropil': 'AL(L)', 'Subregions': 'AL-D(L)'},\n",
    "'AL-DM1(L)': {'System': 'AL(L)', 'Neuropil': 'AL(L)', 'Subregions': 'AL-DM1(L)'},\n",
    "'AL-DM1(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-DM1(R)'},\n",
    "'AL-DM2(L)': {'System': 'AL(L)', 'Neuropil': 'AL(L)', 'Subregions': 'AL-DM2(L)'},\n",
    "'AL-DM2(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-DM2(R)'},\n",
    "'AL-DM3(L)': {'System': 'AL(L)', 'Neuropil': 'AL(L)', 'Subregions': 'AL-DM3(L)'},\n",
    "'AL-DM3(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-DM3(R)'},\n",
    "'AL-DM4(L)': {'System': 'AL(L)', 'Neuropil': 'AL(L)', 'Subregions': 'AL-DM4(L)'},\n",
    "'AL-DM4(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-DM4(R)'},\n",
    "'AL-DM5(L)': {'System': 'AL(L)', 'Neuropil': 'AL(L)', 'Subregions': 'AL-DM5(L)'},\n",
    "'AL-DM5(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-DM5(R)'},\n",
    "'AL-DM6(L)': {'System': 'AL(L)', 'Neuropil': 'AL(L)', 'Subregions': 'AL-DM6(L)'},\n",
    "'AL-DM6(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-DM6(R)'},\n",
    "'AL-DP1l(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-DP1l(R)'},\n",
    "'AL-DP1m(L)': {'System': 'AL(L)', 'Neuropil': 'AL(L)', 'Subregions': 'AL-DP1m(L)'},\n",
    "'AL-DP1m(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-DP1m(R)'},\n",
    "'AL-D(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-D(R)'},\n",
    "'AL-VA1d(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-VA1d(R)'},\n",
    "'AL-VA1v(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-VA1v(R)'},\n",
    "'AL-VA2(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-VA2(R)'},\n",
    "'AL-VA3(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-VA3(R)'},\n",
    "'AL-VA4(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-VA4(R)'},\n",
    "'AL-VA5(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-VA5(R)'},\n",
    "'AL-VA6(L)': {'System': 'AL(L)', 'Neuropil': 'AL(L)', 'Subregions': 'AL-VA6(L)'},\n",
    "'AL-VA6(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-VA6(R)'},\n",
    "'AL-VA7l(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-VA7l(R)'},\n",
    "'AL-VA7m(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-VA7m(R)'},\n",
    "'AL-VC1(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-VC1(R)'},\n",
    "'AL-VC2(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-VC2(R)'},\n",
    "'AL-VC3l(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-VC3l(R)'},\n",
    "'AL-VC3m(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-VC3m(R)'},\n",
    "'AL-VC4(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-VC4(R)'},\n",
    "'AL-VC5(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-VC5(R)'},\n",
    "'AL-VL1(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-VL1(R)'},\n",
    "'AL-VL2a(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-VL2a(R)'},\n",
    "'AL-VL2p(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-VL2p(R)'},\n",
    "'AL-VM1(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-VM1(R)'},\n",
    "'AL-VM2(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-VM2(R)'},\n",
    "'AL-VM3(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-VM3(R)'},\n",
    "'AL-VM4(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-VM4(R)'},\n",
    "'AL-VM5d(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-VM5d(R)'},\n",
    "'AL-VM5v(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-VM5v(R)'},\n",
    "'AL-VM7d(L)': {'System': 'AL(L)', 'Neuropil': 'AL(L)', 'Subregions': 'AL-VM7d(L)'},\n",
    "'AL-VM7d(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-VM7d(R)'},\n",
    "'AL-VM7v(L)': {'System': 'AL(L)', 'Neuropil': 'AL(L)', 'Subregions': 'AL-VM7v(L)'},\n",
    "'AL-VM7v(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-VM7v(R)'},\n",
    "'AL-V(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-V(R)'},\n",
    "'AL-VP5(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-VP5(R)'},\n",
    "'AL-VP4(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-VP4(R)'},\n",
    "'AL-VP3(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-VP3(R)'},\n",
    "'AL-VP2(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-VP2(R)'},\n",
    "'AL-VP1m(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-VP1m(R)'},\n",
    "'AL-VP1l(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-VP1l(R)'},\n",
    "'AL-VP1d(R)': {'System': 'AL(R)', 'Neuropil': 'AL(R)', 'Subregions': 'AL-VP1d(R)'},\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(chunk):\n",
    "    #status = np.nonzero(np.array([i == 'Traced' for i in chunk['status:string'].values]))[0]\n",
    "    status = np.nonzero((chunk['pre:int']+chunk['post:int']!=0).to_numpy())[0]\n",
    "    used = chunk.iloc[status]\n",
    "    #used = chunk\n",
    "    neurons = []\n",
    "\n",
    "    for i, row in used.iterrows():\n",
    "        neuropil_list = []\n",
    "        subregion_list = []\n",
    "        tract_list = []\n",
    "        kk = json.loads(row['roiInfo:string'])\n",
    "        for k, v in kk.items():\n",
    "            if k == \"None\": continue\n",
    "            region = all_brain_regions[k]\n",
    "            if region['Subregions'] is None:\n",
    "                if region['Neuropil'] is None:\n",
    "                    if 'Tract' in region:\n",
    "                        tract_list.append('{}:{}:{}'.format(\n",
    "                            region['Tract'], v.get('pre',0), v.get('post',0)))\n",
    "                    else:\n",
    "                        continue\n",
    "                elif isinstance(region['Neuropil'], list):\n",
    "                    continue\n",
    "                else:\n",
    "                    neuropil_list.append('{}:{}:{}'.format(\n",
    "                        region['Neuropil'], v.get('pre', 0), v.get('post', 0)))\n",
    "            else:\n",
    "                subregion_list.append('{}:{}:{}'.format(\n",
    "                    region['Subregions'], v.get('pre', 0), v.get('post', 0)))\n",
    "\n",
    "        neuropil_list = ';'.join(neuropil_list)\n",
    "        subregion_list = ';'.join(subregion_list)\n",
    "        tract_list = ';'.join(tract_list)\n",
    "\n",
    "        li = [row['bodyId:long'], row['pre:int'], row['post:int'], row['status:string'],\\\n",
    "              row['statusLabel:string'], int(row['cropped:boolean']) if not np.isnan(row['cropped:boolean']) else row['cropped:boolean'], row['instance:string'], \\\n",
    "              row['type:string'], row['cellBodyFiber:string'], row['somaLocation:point{srid:9157}'], \\\n",
    "              row['somaRadius:float'], row['size:long'], neuropil_list, subregion_list,tract_list]\n",
    "        neurons.append(li)\n",
    "    return neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize = 100000\n",
    "\n",
    "with open('neurons_all.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['bodyID','pre','post','status','statusLabel','cropped','instance','type','cellBodyFiber','somaLocation','somaRadius','size','neuropils','subregions','tracts'])\n",
    "    for chunk in tqdm(pd.read_csv('hemibrain_v1.2_neo4j_inputs/Neuprint_Neurons_31597.csv', chunksize=chunksize)):\n",
    "        neurons = process(chunk)\n",
    "        writer.writerows(neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in tqdm(neurons.iterrows()):\n",
    "    bodyID = int(row['bodyID'])\n",
    "    try:\n",
    "        s = c.fetch_skeleton(bodyID, format='pandas')\n",
    "        s.to_csv('swc/{}.swc'.format(bodyID), header=False, index=False, sep=' ')\n",
    "    except HTTPError:\n",
    "        print(bodyID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = pd.read_csv('neurons_all.csv')\n",
    "        \n",
    "traced_neuron_id = neurons['bodyID'].to_numpy()\n",
    "        \n",
    "chunksize = 1000000\n",
    "pre_syn = np.empty((int(2e8),3), np.int64)\n",
    "post_syn = np.empty((int(2e8),3), np.int64)\n",
    "\n",
    "pre_count = 0\n",
    "post_count = 0\n",
    "count = 0\n",
    "for chunk in pd.read_csv('hemibrain_v1.2_neo4j_inputs/Neuprint_SynapseSet_to_Synapses_31597.csv', chunksize=chunksize):\n",
    "    ids = chunk[':START_ID']\n",
    "    pre_site = np.array([[n, int(i.split('_')[0]), int(i.split('_')[1])] \\\n",
    "                         for n,i in enumerate(ids) if i.split('_')[2] == 'pre'])\n",
    "    post_site = np.array([[n, int(i.split('_')[0]), int(i.split('_')[1])] \\\n",
    "                          for n,i in enumerate(ids) if i.split('_')[2] == 'post'])\n",
    "    pre_site_known = pre_site[:,0]\n",
    "    post_site_known = post_site[:,0]\n",
    "    retrieved_pre_site = chunk.iloc[pre_site_known]\n",
    "    pre_site = np.array([[row[':END_ID(Syn-ID)'], int(row[':START_ID'].split('_')[0]), int(row[':START_ID'].split('_')[1])] \\\n",
    "                         for i, row in retrieved_pre_site.iterrows()])\n",
    "    retrieved_post_site = chunk.iloc[post_site_known]\n",
    "    post_site = np.array([[row[':END_ID(Syn-ID)'], int(row[':START_ID'].split('_')[0]), int(row[':START_ID'].split('_')[1])] \\\n",
    "                         for i, row in retrieved_post_site.iterrows()])\n",
    "    if pre_site.size:\n",
    "        pre_syn[pre_count:pre_count+pre_site.shape[0], :] = pre_site\n",
    "        pre_count += pre_site.shape[0]\n",
    "    if post_site.size:\n",
    "        post_syn[post_count:post_count+post_site.shape[0], :] = post_site\n",
    "        post_count += post_site.shape[0]\n",
    "    count += chunksize\n",
    "    print(count, pre_count, post_count)\n",
    "\n",
    "pre_syn = pre_syn[:pre_count,:]\n",
    "post_syn = post_syn[:post_count,:]\n",
    "\n",
    "ind = np.argsort(pre_syn[:,0])\n",
    "pre_syn_sorted = pre_syn[ind, :]\n",
    "ind = np.argsort(post_syn[:,0])\n",
    "post_syn_sorted = post_syn[ind, :]\n",
    "# with h5py.File('syn_pre_post_sorted_by_synapse_id.h5', 'w') as f:\n",
    "#     f['pre_syn_sorted'] = pre_syn_sorted\n",
    "#     f['post_syn_sorted'] = post_syn_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract synapse (pre-site) to synapse (post-site) connection\n",
    "# use only the post synaptic site to get all the synapses because one presynaptic site can have multiple postsynaptic sites\n",
    "# with h5py.File('syn_pre_post_sorted_by_synapse_id.h5', 'r') as f:\n",
    "#     post_syn_sorted = f['post_syn_sorted'][:]\n",
    "post_syn_index = post_syn_sorted[:,0].copy()\n",
    "\n",
    "df = pd.read_csv('hemibrain_v1.2_neo4j_inputs/Neuprint_Synapse_Connections_31597.csv')\n",
    "post_ids = df[':END_ID(Syn-ID)']\n",
    "used = np.where(post_ids.isin(post_syn_index).to_numpy())[0]\n",
    "connections = df.iloc[used].to_numpy()\n",
    "ind = np.argsort(connections[:,1])\n",
    "connections = connections[ind, :]\n",
    "# with h5py.File('synapse_connections.h5', 'w') as f:\n",
    "#     f['synapse_connecions'] = connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract synapse details\n",
    "# with h5py.File('syn_pre_post_sorted_by_synapse_id.h5', 'r') as f:\n",
    "#     pre_syn_sorted = f['pre_syn_sorted'][:]\n",
    "#     post_syn_sorted = f['post_syn_sorted'][:]\n",
    "chunksize = 100000\n",
    "\n",
    "pre_syn_index = list(set(pre_syn_sorted[:,0].copy()))\n",
    "pre_syn_index.extend(list(post_syn_sorted[:,0].copy()))\n",
    "syn_index = np.array(sorted(pre_syn_index))\n",
    "del pre_syn_index#, pre_syn_sorted, post_syn_sorted\n",
    "\n",
    "synapse_array = np.empty((len(syn_index), 6), np.int64)\n",
    "synapse_innervate = np.empty((len(syn_index), 230), np.bool)\n",
    "\n",
    "synapse_count = 0\n",
    "count = 0\n",
    "\n",
    "for chunk in pd.read_csv('hemibrain_v1.2_neo4j_inputs/Neuprint_Synapses_31597.csv', chunksize=chunksize):\n",
    "    ids = chunk[':ID(Syn-ID)']\n",
    "    \n",
    "    start_id = ids.iloc[0]\n",
    "    stop_id = ids.iloc[-1]\n",
    "    pre_start = np.searchsorted(syn_index, start_id, side='left')\n",
    "    pre_end = np.searchsorted(syn_index, stop_id, side='right')\n",
    "    if pre_start >= len(syn_index):\n",
    "        pre_index = []\n",
    "    else:\n",
    "        if pre_end >= len(syn_index):\n",
    "            pre_index = syn_index[pre_start:pre_end] #same as syn_index[pre_start:]\n",
    "        else:\n",
    "            pre_index = syn_index[pre_start:pre_end]\n",
    "    pre_used_synapse = chunk.loc[ids.isin(pre_index)]\n",
    "    li = np.empty((pre_index.size, 6), np.int64)\n",
    "    li1 = np.empty((pre_index.size, 230), np.bool)\n",
    "    i = 0\n",
    "    for _, row in pre_used_synapse.iterrows():\n",
    "        location = eval(row['location:point{srid:9157}'].replace('x', \"'x'\").replace('y', \"'y'\").replace('z', \"'z'\"))\n",
    "        li[i,:] = [row[':ID(Syn-ID)'], # synpase id\n",
    "                     0 if row['type:string'] == 'pre' else 1, #synapse type\n",
    "                     int(row['confidence:float']*1000000), #confidence\n",
    "                     location['x'], location['y'], location['z']]\n",
    "        li1[i,:] = ~np.isnan(np.asarray(row.values[5:], np.double))\n",
    "        i += 1\n",
    "    synapse_array[synapse_count:synapse_count+pre_index.shape[0],:] = li\n",
    "    synapse_innervate[synapse_count:synapse_count+pre_index.shape[0],:] = li1\n",
    "    synapse_count += pre_index.shape[0]\n",
    "    count += chunksize\n",
    "    print(count, len(pre_used_synapse))\n",
    "synapse_array = synapse_array[:synapse_count,:]\n",
    "synapse_innervate = synapse_innervate[:synapse_count,:]\n",
    "\n",
    "# with h5py.File('syn_used_details.h5', 'w') as f:\n",
    "#     f['synapse_array'] = synapse_array\n",
    "#     f['synapse_innervate'] = synapse_innervate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder synapses\n",
    "\n",
    "# with h5py.File('syn_used_details.h5', 'r') as f:\n",
    "#     synapse_array = f['synapse_array'][:]\n",
    "#     synapse_innervate = f['synapse_innervate']\n",
    "\n",
    "# with h5py.File('synapse_connections.h5', 'r') as f:\n",
    "#     synapse_connections = f['synapse_connecions'][:]\n",
    "\n",
    "# with h5py.File('syn_pre_post_sorted_by_synapse_id.h5', 'r') as f:\n",
    "#     pre_syn_sorted = f['pre_syn_sorted'][:]\n",
    "#     post_syn_sorted = f['post_syn_sorted'][:]\n",
    "\n",
    "synapse_connections = connections\n",
    "    \n",
    "ids = synapse_array[:,0]\n",
    "syn_id_dict = {j: i for i, j in enumerate(ids)}\n",
    "# ids = pre_syn_sorted[:,0]\n",
    "# pre_syn_id_dict = {j: i for i, j in enumerate(ids)} # map syn id to pre_syn_sorted\n",
    "ids = post_syn_sorted[:,0]\n",
    "post_syn_id_dict = {j: i for i, j in enumerate(ids)} # map syn id to post_syn_sorted\n",
    "\n",
    "synapse_dict = {}\n",
    "wrong_synapse = 0\n",
    "for i, pair in tqdm(enumerate(synapse_connections)):\n",
    "    pre_syn_id = pair[0]\n",
    "    post_syn_id = pair[1]\n",
    "    post_id = post_syn_id_dict[post_syn_id]\n",
    "    post_info = synapse_array[syn_id_dict[post_syn_id]]\n",
    "    post_info1 = synapse_innervate[syn_id_dict[post_syn_id]]\n",
    "    post_neuron_id, pre_neuron_id = post_syn_sorted[post_id, 1:]\n",
    "\n",
    "    #if len(np.where((pre_syn_sorted == (pre_syn_id, pre_neuron_id, post_neuron_id)).all(axis=1))[0]) != 1:\n",
    "    #    print(pre_syn_id, post_syn_id)\n",
    "    # pre_id = pre_syn_id_dict[pre_syn_id]\n",
    "    pre_info = synapse_array[syn_id_dict[pre_syn_id]]\n",
    "    pre_info1 = synapse_innervate[syn_id_dict[pre_syn_id]]\n",
    "\n",
    "    if pre_neuron_id not in synapse_dict:\n",
    "        synapse_dict[pre_neuron_id] = {}\n",
    "    pre_dict = synapse_dict[pre_neuron_id]\n",
    "    if post_neuron_id not in synapse_dict[pre_neuron_id]:\n",
    "        pre_dict[post_neuron_id] =  {'pre_synapse_ids': [],\n",
    "                                     'post_synapse_ids': [],\n",
    "                                     'pre_confidence': [],\n",
    "                                     'post_confidence': [],\n",
    "                                     'pre_x': [],\n",
    "                                     'pre_y': [],\n",
    "                                     'pre_z': [],\n",
    "                                     'post_x': [],\n",
    "                                     'post_y': [],\n",
    "                                     'post_z': [],\n",
    "                                     'regions': np.zeros(230, np.int32)}\n",
    "    info_dict = pre_dict[post_neuron_id]\n",
    "    info_dict['pre_synapse_ids'].append(pre_syn_id)\n",
    "    info_dict['post_synapse_ids'].append(post_syn_id)\n",
    "    info_dict['pre_confidence'].append(pre_info[2])\n",
    "    info_dict['post_confidence'].append(post_info[2])\n",
    "    info_dict['pre_x'].append(pre_info[3])\n",
    "    info_dict['pre_y'].append(pre_info[4])\n",
    "    info_dict['pre_z'].append(pre_info[5])\n",
    "    info_dict['post_x'].append(post_info[3])\n",
    "    info_dict['post_y'].append(post_info[4])\n",
    "    info_dict['post_z'].append(post_info[5])\n",
    "    info_dict['regions'] += post_info1\n",
    "\n",
    "chunk = pd.read_csv('hemibrain_v1.2_neo4j_inputs/Neuprint_Synapses_31597.csv', chunksize=1).get_chunk()\n",
    "labels = [i.split(':')[0] for i in chunk.columns.to_list()]\n",
    "regions = labels[5:]\n",
    "\n",
    "with open('synapses_all.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['pre_id','post_id','N','pre_confidence','post_confidence',\\\n",
    "                     'pre_x','pre_y','pre_z','post_x','post_y','post_z',\\\n",
    "                     'neuropils','subregions','tracts'])\n",
    "    for pre, k in tqdm(synapse_dict.items()):\n",
    "        for post, v in k.items():\n",
    "            reg = {regions[i]: v['regions'][i] for i in np.nonzero(v['regions'])[0]}\n",
    "            neuropil_list = []\n",
    "            subregion_list = []\n",
    "            tract_list = []\n",
    "            for k, n in reg.items():\n",
    "                region = all_brain_regions[k]\n",
    "                if region['Subregions'] is None:\n",
    "                    if region['Neuropil'] is None:\n",
    "                        if 'Tract' in region:\n",
    "                            tract_list.append('{}:{}'.format(\n",
    "                                region['Tract'], n))\n",
    "                        else:\n",
    "                            continue\n",
    "                    elif isinstance(region['Neuropil'], list):\n",
    "                        continue\n",
    "                    else:\n",
    "                        neuropil_list.append('{}:{}'.format(\n",
    "                            region['Neuropil'], n))\n",
    "                else:\n",
    "                    subregion_list.append('{}:{}'.format(\n",
    "                        region['Subregions'], n))\n",
    "\n",
    "            neuropil_list = ';'.join(neuropil_list)\n",
    "            subregion_list = ';'.join(subregion_list)\n",
    "            tract_list = ';'.join(tract_list)\n",
    "            writer.writerow([pre, post, len(v['pre_x']), str(v['pre_confidence']), \\\n",
    "                             str(v['post_confidence']), str(v['pre_x']), str(v['pre_y']), str(v['pre_z']), \\\n",
    "                             str(v['post_x']), str(v['post_y']), str(v['post_z']), \\\n",
    "                             neuropil_list, subregion_list, tract_list])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading NeuroArch Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %reset\n",
    "import neuroarch.na as na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('hemibrain_referenceID_to_uname.json') as f:\n",
    "    neuron_ref_to_obj = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and connect to database. mode 'o' overwrites the entire database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemibrain = na.NeuroArch('hemibrain', mode = 'o', version = \"2.0\",\n",
    "                         maintainer_name = \"\", maintainer_email = \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species = hemibrain.add_Species('Drosophila melanogaster', stage = 'adult',\n",
    "                                sex = 'female',\n",
    "                                synonyms = ['fruit fly', 'common fruit fly', 'vinegar fly'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a datasource under the species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = '1.2.1'\n",
    "datasource = hemibrain.add_DataSource('Hemibrain', version = version,\n",
    "                                      url = 'https://www.janelia.org/project-team/flyem/hemibrain',\n",
    "                                      species = species)\n",
    "hemibrain.default_DataSource = datasource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create subsystems, tracts, neuropils and subregions under the datasource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in all_brain_regions.items():\n",
    "    if v['Neuropil'] is None and v['Subregions'] is None:\n",
    "        if 'System' in v:\n",
    "            hemibrain.add_Subsystem(k)\n",
    "    elif 'System' in v:\n",
    "        if v['Neuropil'] == v['System'] and v['Subregions'] is None:\n",
    "            hemibrain.add_Subsystem(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mesh are then downsampled using [MeshLab](https://www.meshlab.net/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in all_brain_regions.items():\n",
    "    if v['Neuropil'] is None and v['Subregions'] is None:\n",
    "        if 'Tract' in v:\n",
    "            ms = ml.MeshSet()\n",
    "            ms.load_new_mesh(\"roi/{}.obj\".format(k))\n",
    "            ms.load_filter_script('filter_file_tmp.mlx')\n",
    "            ms.apply_filter_script()\n",
    "            current_mesh = ms.current_mesh()\n",
    "            hemibrain.add_Tract(k, morphology = {'type': 'mesh', \n",
    "                                                 \"vertices\": (current_mesh.vertex_matrix()*0.008).flatten().tolist(),\n",
    "                                                 \"faces\": current_mesh.face_matrix().flatten().tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in all_brain_regions.items():\n",
    "    if v['Neuropil'] is not None and v['Subregions'] is None:\n",
    "        if isinstance(v['Neuropil'], list):\n",
    "            continue\n",
    "        ms = ml.MeshSet()\n",
    "        ms.load_new_mesh(\"roi/{}.obj\".format(k))\n",
    "        ms.load_filter_script('filter_file_tmp.mlx')\n",
    "        ms.apply_filter_script()\n",
    "        current_mesh = ms.current_mesh()\n",
    "        hemibrain.add_Neuropil(k,\n",
    "                               morphology = {'type': 'mesh',\n",
    "                                             \"vertices\": (current_mesh.vertex_matrix()*0.008).flatten().tolist(),\n",
    "                                             \"faces\": current_mesh.face_matrix().flatten().tolist()},\n",
    "                               subsystem = v['System'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in all_brain_regions.items():\n",
    "    if v['Subregions'] is not None:\n",
    "        if isinstance(v['Neuropil'], list):\n",
    "            continue\n",
    "        ms = ml.MeshSet()\n",
    "        ms.load_new_mesh(\"roi/{}.obj\".format(k))\n",
    "        ms.load_filter_script('filter_file_tmp.mlx')\n",
    "        ms.apply_filter_script()\n",
    "        current_mesh = ms.current_mesh()\n",
    "        hemibrain.add_Subregion(k,\n",
    "                                morphology = {'type': 'mesh',\n",
    "                                              \"vertices\": (current_mesh.vertex_matrix()*0.008).flatten().tolist(),\n",
    "                                              \"faces\": current_mesh.face_matrix().flatten().tolist()},\n",
    "                                neuropil = v['Neuropil'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_swc(file_name):\n",
    "    df = pd.read_csv(file_name, sep = ' ', header = None, comment = '#', index_col = False,\n",
    "                     names = ['sample', 'x', 'y', 'z', 'r', 'parent'],\n",
    "                    skipinitialspace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_list = pd.read_csv('neurons_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swc_dir = 'swc'\n",
    "uname_dict = {}\n",
    "segment_ids = set()\n",
    "added = 0\n",
    "unadded = []\n",
    "to_combine = []\n",
    "\n",
    "choose = ((neuron_list['status']=='Traced') & (neuron_list['statusLabel']!='Leaves')) | (~neuron_list['instance'].isna())\n",
    "\n",
    "for i, row in tqdm(neuron_list[choose].iterrows()):\n",
    "    bodyID = row['bodyID']\n",
    "    cell_type = row['type']\n",
    "    name = row['instance']\n",
    "    segment = False\n",
    "    \n",
    "    if not isinstance(name, str):\n",
    "        if isinstance(cell_type, str):\n",
    "            name = '{}_{}'.format(cell_type, bodyID)\n",
    "        else:\n",
    "            if row['status'] in ['Traced', 'Unimportant']:\n",
    "                cell_type = 'unknown'\n",
    "                name = 'unknown_{}'.format(bodyID)\n",
    "            else:\n",
    "                segment = True\n",
    "                \n",
    "    else:\n",
    "        if not isinstance(cell_type, str):\n",
    "            cell_type = 'unknown'\n",
    "            if not isinstance(name, str):\n",
    "                name = '{}_{}'.format(cell_type, bodyID)\n",
    "            else:\n",
    "                name = '{}_{}'.format(name, bodyID)\n",
    "        else:\n",
    "            try:\n",
    "                name = neuron_ref_to_obj[str(bodyID)] #'{}_{}'.format(name, uname_dict[name])\n",
    "            except KeyError:\n",
    "                if os.path.exists('{}/{}.swc'.format(swc_dir, bodyID)):\n",
    "                    unadded.append(bodyID)\n",
    "                    continue\n",
    "                else:\n",
    "                    unadded.append(bodyID)\n",
    "                    continue\n",
    "                \n",
    "    info = {}\n",
    "    \n",
    "    added += 1\n",
    "    \n",
    "    c_neuropils = row['neuropils']\n",
    "    c_subregions = row['subregions']\n",
    "    c_tracts = row['tracts']\n",
    "    arborization = []\n",
    "    if isinstance(c_neuropils, str):\n",
    "        dendrites = {j.split(':')[0]: int(j.split(':')[2]) for j in c_neuropils.split(';') if int(j.split(':')[2]) > 0}\n",
    "        axons = {j.split(':')[0]: int(j.split(':')[1]) for j in c_neuropils.split(';') if int(j.split(':')[1]) > 0}\n",
    "        arborization.append({'dendrites': dendrites, 'axons': axons, 'type': 'neuropil'})\n",
    "    if isinstance(c_subregions, str):\n",
    "        dendrites = {j.split(':')[0]: int(j.split(':')[2]) for j in c_subregions.split(';') if int(j.split(':')[2]) > 0}\n",
    "        axons = {j.split(':')[0]: int(j.split(':')[1]) for j in c_subregions.split(';') if int(j.split(':')[1]) > 0}\n",
    "        arborization.append({'dendrites': dendrites, 'axons': axons, 'type': 'subregion'})\n",
    "    if isinstance(c_tracts, str):\n",
    "        dendrites = {j.split(':')[0]: int(j.split(':')[2]) for j in c_tracts.split(';') if int(j.split(':')[2]) > 0}\n",
    "        axons = {j.split(':')[0]: int(j.split(':')[1]) for j in c_tracts.split(';') if int(j.split(':')[1]) > 0}\n",
    "        arborization.append({'dendrites': dendrites, 'axons': axons, 'type': 'tract'})\n",
    "    \n",
    "    try:\n",
    "        df = load_swc('{}/{}.swc'.format(swc_dir, bodyID))\n",
    "        morphology = {'x': (df['x']*0.008).tolist(),\n",
    "                      'y': (df['y']*0.008).tolist(),\n",
    "                      'z': (df['z']*0.008).tolist(),\n",
    "                      'r': (df['r']*0.008).tolist(),\n",
    "                      'parent': df['parent'].tolist(),\n",
    "                      'identifier': [0]*(len(df['x'])),\n",
    "                      'sample': df['sample'].tolist(),\n",
    "                      'type': 'swc'}\n",
    "    except FileNotFoundError:\n",
    "        morphology = None\n",
    "        if segment: # no name, not traced, no morph\n",
    "            to_combine.append(bodyID)\n",
    "            continue\n",
    "        else:\n",
    "            segment = True\n",
    "    \n",
    "    if isinstance(row['statusLabel'], str):\n",
    "        info['Hemibrain Trace Status'] = row['statusLabel']\n",
    "    else:\n",
    "        info['Hemibrain Trace Status'] = 'Untraced'\n",
    "\n",
    "    if not segment:\n",
    "        hemibrain.add_Neuron(name, # uname\n",
    "                             cell_type, # name\n",
    "                             referenceId = str(bodyID), #referenceId\n",
    "                             info = info if len(info) else None,\n",
    "                             morphology = morphology,\n",
    "                             arborization = arborization)\n",
    "    else:\n",
    "        cell_type = 'segment'\n",
    "        name = 'segment_{}'.format(bodyID)\n",
    "        hemibrain.add_NeuronFragment(name,\n",
    "                                     cell_type,\n",
    "                                     referenceId = str(bodyID),\n",
    "                                     info = info if len(info) else None,\n",
    "                                     morphology = morphology,\n",
    "                                     arborization = arborization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = neuron_list[neuron_list['bodyID'].isin(unadded)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in tqdm(df.iterrows()):\n",
    "    bodyID = row['bodyID']\n",
    "    cell_type = row['type']\n",
    "    name = row['instance']\n",
    "    \n",
    "    other_neurons = hemibrain.sql_query('select from Neuron where uname matches \"{}_[0-9]+\"'.format(name))\n",
    "    if len(other_neurons):\n",
    "        assert max([int(n.uname.split('_')[-1]) for n in other_neurons.nodes_as_objs]) == len(other_neurons)\n",
    "        N = len(other_neurons) + 1\n",
    "    else:\n",
    "        N = 1\n",
    "    \n",
    "    name = '{}_{}'.format(name, N)    \n",
    "                \n",
    "    info = {}\n",
    "    segment = False\n",
    "    \n",
    "    c_neuropils = row['neuropils']\n",
    "    c_subregions = row['subregions']\n",
    "    c_tracts = row['tracts']\n",
    "    arborization = []\n",
    "    if isinstance(c_neuropils, str):\n",
    "        dendrites = {j.split(':')[0]: int(j.split(':')[2]) for j in c_neuropils.split(';') if int(j.split(':')[2]) > 0}\n",
    "        axons = {j.split(':')[0]: int(j.split(':')[1]) for j in c_neuropils.split(';') if int(j.split(':')[1]) > 0}\n",
    "        arborization.append({'dendrites': dendrites, 'axons': axons, 'type': 'neuropil'})\n",
    "    if isinstance(c_subregions, str):\n",
    "        dendrites = {j.split(':')[0]: int(j.split(':')[2]) for j in c_subregions.split(';') if int(j.split(':')[2]) > 0}\n",
    "        axons = {j.split(':')[0]: int(j.split(':')[1]) for j in c_subregions.split(';') if int(j.split(':')[1]) > 0}\n",
    "        arborization.append({'dendrites': dendrites, 'axons': axons, 'type': 'subregion'})\n",
    "    if isinstance(c_tracts, str):\n",
    "        dendrites = {j.split(':')[0]: int(j.split(':')[2]) for j in c_tracts.split(';') if int(j.split(':')[2]) > 0}\n",
    "        axons = {j.split(':')[0]: int(j.split(':')[1]) for j in c_tracts.split(';') if int(j.split(':')[1]) > 0}\n",
    "        arborization.append({'dendrites': dendrites, 'axons': axons, 'type': 'tract'})\n",
    "    \n",
    "    try:\n",
    "        df = load_swc('{}/{}.swc'.format(swc_dir, bodyID))\n",
    "        morphology = {'x': (df['x']*0.008).tolist(),\n",
    "                      'y': (df['y']*0.008).tolist(),\n",
    "                      'z': (df['z']*0.008).tolist(),\n",
    "                      'r': (df['r']*0.008).tolist(),\n",
    "                      'parent': df['parent'].tolist(),\n",
    "                      'identifier': [0]*(len(df['x'])),\n",
    "                      'sample': df['sample'].tolist(),\n",
    "                      'type': 'swc'}\n",
    "    except FileNotFoundError:\n",
    "        morphology = None\n",
    "        segment = True\n",
    "    \n",
    "    if isinstance(row['statusLabel'], str):\n",
    "        info['Hemibrain Trace Status'] = row['statusLabel']\n",
    "    else:\n",
    "        info['Hemibrain Trace Status'] = 'Untraced'\n",
    "    \n",
    "    hemibrain.add_Neuron(name, # uname\n",
    "                         cell_type, # name\n",
    "                         referenceId = str(bodyID), #referenceId\n",
    "                         info = info if len(info) else None,\n",
    "                         morphology = morphology,\n",
    "                         arborization = arborization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_chosen = neuron_list[~choose]\n",
    "for i, row in tqdm(not_chosen.iterrows()):\n",
    "    bodyID = row['bodyID']\n",
    "\n",
    "    if not os.path.exists('{}/{}.swc'.format(swc_dir, bodyID)):\n",
    "        continue\n",
    "\n",
    "    cell_type = 'segment'\n",
    "    name = 'segment_{}'.format(bodyID)\n",
    "\n",
    "    info = {}\n",
    "\n",
    "    added += 1\n",
    "\n",
    "    c_neuropils = row['neuropils']\n",
    "    c_subregions = row['subregions']\n",
    "    c_tracts = row['tracts']\n",
    "    arborization = []\n",
    "    if isinstance(c_neuropils, str):\n",
    "        dendrites = {j.split(':')[0]: int(j.split(':')[2]) for j in c_neuropils.split(';') if int(j.split(':')[2]) > 0}\n",
    "        axons = {j.split(':')[0]: int(j.split(':')[1]) for j in c_neuropils.split(';') if int(j.split(':')[1]) > 0}\n",
    "        arborization.append({'dendrites': dendrites, 'axons': axons, 'type': 'neuropil'})\n",
    "    if isinstance(c_subregions, str):\n",
    "        dendrites = {j.split(':')[0]: int(j.split(':')[2]) for j in c_subregions.split(';') if int(j.split(':')[2]) > 0}\n",
    "        axons = {j.split(':')[0]: int(j.split(':')[1]) for j in c_subregions.split(';') if int(j.split(':')[1]) > 0}\n",
    "        arborization.append({'dendrites': dendrites, 'axons': axons, 'type': 'subregion'})\n",
    "    if isinstance(c_tracts, str):\n",
    "        dendrites = {j.split(':')[0]: int(j.split(':')[2]) for j in c_tracts.split(';') if int(j.split(':')[2]) > 0}\n",
    "        axons = {j.split(':')[0]: int(j.split(':')[1]) for j in c_tracts.split(';') if int(j.split(':')[1]) > 0}\n",
    "        arborization.append({'dendrites': dendrites, 'axons': axons, 'type': 'tract'})\n",
    "    \n",
    "    df = load_swc('{}/{}.swc'.format(swc_dir, bodyID))\n",
    "    morphology = {'x': (df['x']*0.008).tolist(),\n",
    "                  'y': (df['y']*0.008).tolist(),\n",
    "                  'z': (df['z']*0.008).tolist(),\n",
    "                  'r': (df['r']*0.008).tolist(),\n",
    "                  'parent': df['parent'].tolist(),\n",
    "                  'identifier': [0]*(len(df['x'])),\n",
    "                  'sample': df['sample'].tolist(),\n",
    "                  'type': 'swc'}\n",
    "    if isinstance(row['statusLabel'], str):\n",
    "        info['Hemibrain Trace Status'] = row['statusLabel']\n",
    "    else:\n",
    "        info['Hemibrain Trace Status'] = 'Untraced'\n",
    "\n",
    "    hemibrain.add_NeuronFragment(name,\n",
    "                                 cell_type,\n",
    "                                 referenceId = str(bodyID),\n",
    "                                 info = info if len(info) else None,\n",
    "                                 morphology = morphology,\n",
    "                                 arborization = arborization)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemibrain.flush_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuroarch.na as na\n",
    "hemibrain = na.NeuroArch('hemibrain', mode = 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemibrain.default_DataSource = hemibrain.find_objs('DataSource', name = 'Hemibrain')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemibrain.reconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all the neurons so they can be keyed by their referenceId.\n",
    "neurons = hemibrain.sql_query('select from NeuronAndFragment').node_objs\n",
    "# set the cache so there is no need for database access.\n",
    "for neuron in neurons:\n",
    "    hemibrain.set('NeuronAndFragment', neuron.uname, neuron, hemibrain.default_DataSource)\n",
    "neuron_ref_to_obj = {int(neuron.referenceId): neuron for neuron in neurons}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load synapses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = {}\n",
    "morph_dict = {}\n",
    "\n",
    "for chunk in tqdm(pd.read_csv('synapses_all.csv', chunksize=100000)):\n",
    "    for i, row in chunk.iterrows():\n",
    "        pre = int(row['pre_id'])\n",
    "        post = int(row['post_id'])\n",
    "        if pre not in neuron_ref_to_obj:\n",
    "            pre = -1\n",
    "        if post not in neuron_ref_to_obj:\n",
    "            post = -1\n",
    "        if pre == -1 and post == -1:\n",
    "            continue\n",
    "        \n",
    "        pre_conf = np.array(eval(row['pre_confidence']))/1e6\n",
    "        post_conf = np.array(eval(row['post_confidence']))/1e6\n",
    "        NHP = np.sum(np.logical_and(post_conf>=0.7, pre_conf>=0.7))\n",
    "        \n",
    "        if pre == -1:\n",
    "            if post not in tmp:\n",
    "                tmp[post] = {}\n",
    "            if 'pre' not in tmp[post]:\n",
    "                tmp[post]['pre'] = {'pre_x': [], 'pre_y': [], 'pre_z': [], 'post_x': [], 'post_y': [], 'post_z': [],\n",
    "                                    'pre_confidence': [], 'post_confidence': [],\n",
    "                                    'N': 0, 'NHP': 0}\n",
    "            tmp[post]['pre']['pre_x'].append(np.array(eval(row['pre_x']))*0.008)\n",
    "            tmp[post]['pre']['pre_y'].append(np.array(eval(row['pre_y']))*0.008)\n",
    "            tmp[post]['pre']['pre_z'].append(np.array(eval(row['pre_z']))*0.008)\n",
    "            tmp[post]['pre']['post_x'].append(np.array(eval(row['post_x']))*0.008)\n",
    "            tmp[post]['pre']['post_y'].append(np.array(eval(row['post_y']))*0.008)\n",
    "            tmp[post]['pre']['post_z'].append(np.array(eval(row['post_z']))*0.008)\n",
    "            tmp[post]['pre']['pre_confidence'].append(pre_conf)\n",
    "            tmp[post]['pre']['post_confidence'].append(post_conf)\n",
    "            tmp[post]['pre']['N'] += row['N']\n",
    "            tmp[post]['pre']['NHP'] += NHP                        \n",
    "        elif post == -1:\n",
    "            if pre not in tmp:\n",
    "                tmp[pre] = {}\n",
    "            if 'post' not in tmp[pre]:\n",
    "                tmp[pre]['post'] = {'pre_x': [], 'pre_y': [], 'pre_z': [], 'post_x': [], 'post_y': [], 'post_z': [],\n",
    "                                    'pre_confidence': [], 'post_confidence': [],\n",
    "                                    'N': 0, 'NHP': 0}\n",
    "            tmp[pre]['post']['pre_x'].append(np.array(eval(row['pre_x']))*0.008)\n",
    "            tmp[pre]['post']['pre_y'].append(np.array(eval(row['pre_y']))*0.008)\n",
    "            tmp[pre]['post']['pre_z'].append(np.array(eval(row['pre_z']))*0.008)\n",
    "            tmp[pre]['post']['post_x'].append(np.array(eval(row['post_x']))*0.008)\n",
    "            tmp[pre]['post']['post_y'].append(np.array(eval(row['post_y']))*0.008)\n",
    "            tmp[pre]['post']['post_z'].append(np.array(eval(row['post_z']))*0.008)\n",
    "            tmp[pre]['post']['pre_confidence'].append(pre_conf)\n",
    "            tmp[pre]['post']['post_confidence'].append(post_conf)\n",
    "            tmp[pre]['post']['N'] += row['N']\n",
    "            tmp[pre]['post']['NHP'] += NHP\n",
    "        else:\n",
    "            pre_neuron = neuron_ref_to_obj[pre]\n",
    "            post_neuron = neuron_ref_to_obj[post]\n",
    "            c_neuropils = row['neuropils']\n",
    "            c_subregions = row['subregions']\n",
    "            c_tracts = row['tracts']\n",
    "            arborization = []\n",
    "            neuropils = {}\n",
    "            if isinstance(c_neuropils, str):\n",
    "                arborization.append({'type': 'neuropil',\n",
    "                               'synapses': {j.split(':')[0]: int(j.split(':')[1]) \\\n",
    "                                            for j in c_neuropils.split(';') \\\n",
    "                                            if int(j.split(':')[1]) > 0}})\n",
    "            if isinstance(c_subregions, str):\n",
    "                arborization.append({'type': 'subregion',\n",
    "                                     'synapses': {j.split(':')[0]: int(j.split(':')[1]) \\\n",
    "                                                  for j in c_subregions.split(';') \\\n",
    "                                                  if int(j.split(':')[1]) > 0}})\n",
    "            if isinstance(c_tracts, str):\n",
    "                arborization.append({'type': 'tract',\n",
    "                                     'synapses': {j.split(':')[0]: int(j.split(':')[1]) \\\n",
    "                                                  for j in c_tracts.split(';') \\\n",
    "                                                  if int(j.split(':')[1]) > 0}})\n",
    "            content = {'type': 'swc'}\n",
    "            content['x'] = (np.array(eval(row['pre_x'])+eval(row['post_x']))*0.008).tolist()\n",
    "            content['y'] = (np.array(eval(row['pre_y'])+eval(row['post_y']))*0.008).tolist()\n",
    "            content['z'] = (np.array(eval(row['pre_z'])+eval(row['post_z']))*0.008).tolist()\n",
    "            content['r'] = [0]*len(content['x'])\n",
    "            content['parent'] = [-1]*(len(content['x'])//2) + [i+1 for i in range(len(content['x'])//2)]\n",
    "            content['identifier'] = [7]*(len(content['x'])//2) + [8]*(len(content['x'])//2)\n",
    "            content['sample'] = [i+1 for i in range(len(content['x']))]\n",
    "            content['confidence'] = pre_conf.tolist() + post_conf.tolist()\n",
    "\n",
    "            synapse = hemibrain.add_Synapse(pre_neuron, post_neuron, N = row['N'], NHP = NHP)\n",
    "            morph_dict[synapse._id] = {'morphology': content,\n",
    "                                       'arborization': arborization}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemibrain.flush_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = '2.0\n",
    "species = hemibrain.sql_query('select from Species').node_objs[0]\n",
    "notional_datasource = hemibrain.add_DataSource('notional', version = version,\n",
    "                                         species = species)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, v in tqdm(tmp.items()):\n",
    "    if 'pre' in v:\n",
    "        post_neuron = neuron_ref_to_obj[n]\n",
    "        cell_type = 'combined_untraced_segments'\n",
    "        name = 'segments_presynaptic_to_{}'.format(post_neuron.uname)\n",
    "        pre_neuron = hemibrain.add_NeuronFragment(\n",
    "                                     name,\n",
    "                                     cell_type,\n",
    "                                     data_source = notional_datasource)\n",
    "        \n",
    "        content = {'type': 'swc'}\n",
    "        content['x'] = np.concatenate(v['pre']['pre_x'] + v['pre']['post_x']).tolist()\n",
    "        content['y'] = np.concatenate(v['pre']['pre_y'] + v['pre']['post_y']).tolist()\n",
    "        content['z'] = np.concatenate(v['pre']['pre_z'] + v['pre']['post_z']).tolist()\n",
    "        content['r'] = [0]*len(content['x'])\n",
    "        content['parent'] = [-1]*(len(content['x'])//2) + [i+1 for i in range(len(content['x'])//2)]\n",
    "        content['identifier'] = [7]*(len(content['x'])//2) + [8]*(len(content['x'])//2)\n",
    "        content['sample'] = [i+1 for i in range(len(content['x']))]\n",
    "        content['confidence'] = np.concatenate(v['pre']['pre_confidence'] + v['pre']['post_confidence']).tolist()\n",
    "        synapse = hemibrain.add_Synapse(pre_neuron, post_neuron, N = v['pre']['N'], NHP = v['pre']['NHP'])\n",
    "        morph_dict[synapse._id] = {'morphology': content}\n",
    "    if 'post' in v:\n",
    "        pre_neuron = neuron_ref_to_obj[n]\n",
    "        cell_type = 'combined_untraced_segments'\n",
    "        name = 'segments_postsynaptic_to_{}'.format(pre_neuron.uname)\n",
    "        post_neuron = hemibrain.add_NeuronFragment(\n",
    "                                     name,\n",
    "                                     cell_type,\n",
    "                                     data_source = notional_datasource)\n",
    "        content = {'type': 'swc'}\n",
    "        content['x'] = np.concatenate(v['post']['pre_x'] + v['post']['post_x']).tolist()\n",
    "        content['y'] = np.concatenate(v['post']['pre_y'] + v['post']['post_y']).tolist()\n",
    "        content['z'] = np.concatenate(v['post']['pre_z'] + v['post']['post_z']).tolist()\n",
    "        content['r'] = [0]*len(content['x'])\n",
    "        content['parent'] = [-1]*(len(content['x'])//2) + [i+1 for i in range(len(content['x'])//2)]\n",
    "        content['identifier'] = [7]*(len(content['x'])//2) + [8]*(len(content['x'])//2)\n",
    "        content['sample'] = [i+1 for i in range(len(content['x']))]\n",
    "        content['confidence'] = np.concatenate(v['post']['pre_confidence'] + v['post']['post_confidence']).tolist()\n",
    "        synapse = hemibrain.add_Synapse(pre_neuron, post_neuron, N = v['post']['N'], NHP = v['post']['NHP'])\n",
    "        morph_dict[synapse._id] = {'morphology': content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemibrain.flush_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rid, data in tqdm(morph_dict.items()):\n",
    "    if 'morphology' in data:\n",
    "        hemibrain.add_morphology(rid, data['morphology'])\n",
    "    if 'arborization' in data:\n",
    "        hemibrain.add_synapse_arborization(rid, data['arborization'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
