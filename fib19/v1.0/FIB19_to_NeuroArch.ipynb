{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab5ff272",
   "metadata": {},
   "source": [
    "This tutorial provides code to load NeuroArch database with FIB19 Optic Lobe Dataset v1.0. Requirement before running the notebook:,\n",
    "- Installed [NeuroArch](https://github.com/fruitflybrain/neuroarch), [OrientDB Community Version](https://www.orientdb.org/download) version 3.1.x, and [pyorient](https://github.com/fruitflybrain/pyorient). The [NeuroNLP Docker image](https://hub.docker.com/r/fruitflybrain/neuronlp) and [FlyBrainLab Docker image](https://hub.docker.com/r/fruitflybrain/fbl) all have a copy of the software requirement ready.\n",
    "- Have more than 3 GB free disk space (for NeuroArch database).\n",
    "\n",
    "A backup of the database created by this notebook can be downloaded [here](https://drive.google.com/file/d/11TJlrASgf6HlhLNrnoAZ8trd8cbcToOM/view?usp=drive_link). To restore it in OrientDB, run\n",
    "```\n",
    "/path/to/orientdb/bin/console.sh \"create database plocal:../databases/hemibrain admin admin; restore database /path/to/fib19_1.0_na_v1.0.0_backup.zip\"\\n\",\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc21a40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import subprocess\n",
    "import csv\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import neuroarch.na as na"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2406f265",
   "metadata": {},
   "source": [
    "## Create a new database\n",
    "Create a new database called `fib19`, open it in overwrite mode so any old `fib19` folder under `orientdb/databases/` will be removed and recreated. Using default OrientDB binary port `2424`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2c4908",
   "metadata": {},
   "outputs": [],
   "source": [
    "fib19 = na.NeuroArch('fib19',  mode = 'o', version = \"1.0.0\", port = 2424,\n",
    "                     maintainer_name = \"\", maintainer_email = \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc193d4",
   "metadata": {},
   "source": [
    "## Specify the species and datasource\n",
    "We add two datasource, one from FIB19 and another from transcriptome data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c831ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "species = fib19.add_Species('Drosophila melanogaster', stage = 'adult',\n",
    "                            sex = 'female',\n",
    "                            synonyms = ['fruit fly', 'common fruit fly', 'vinegar fly'])\n",
    "version = '1.0'\n",
    "datasource = fib19.add_DataSource('fib19', version = version,\n",
    "                                url = 'https://emdata.janelia.org/#/repo/73581d2d46fc445d83cf98382b566b55',\n",
    "                                species = species)\n",
    "fib19.default_DataSource = datasource\n",
    "transcriptome_datasource = fib19.add_DataSource('GSE116969', version = '1.0',\n",
    "                                                  url = 'https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE116969',\n",
    "                                                  description = 'Fred P Davis, Aljoscha Nern, Serge Picard, Michael B Reiser, Gerald M Rubin, Sean R Eddy, Gilbert L Henry, A genetic, genomic, and computational resource for exploring neural circuit function. eLife 2020;9:e50901. DOI: 10.7554/eLife.50901',\n",
    "                                                  species = species)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86deec10",
   "metadata": {},
   "source": [
    "## Add Regions\n",
    "Adding subsystem and neuropils.\n",
    "Note that the neuropil mesh is provided in $\\mu$m unit, so we don't need to scale it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6def0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fib19.add_Subsystem('OL(R)', synonyms = ['right optic lobe'])\n",
    "all_rois = {\n",
    "    'LO': {'System': 'OL(R)', 'Neuropil': 'LO(R)', 'synonyms': 'right Lobula'},\n",
    "    'ME': {'System': 'OL(R)', 'Neuropil': 'ME(R)', 'synonyms': 'right Medulla'},\n",
    "    'LOP': {'System': 'OL(R)', 'Neuropil': 'LOP(R)', 'synonyms': 'right Lobula Plate'},\n",
    "}\n",
    "for k, v in all_rois.items():\n",
    "    if v['Neuropil'] is not None:\n",
    "        ms = ml.MeshSet()\n",
    "        ms.load_new_mesh(\"roi/{}.obj\".format(k))\n",
    "        current_mesh = ms.current_mesh()\n",
    "        fib19.add_Neuropil(v['Neuropil'],\n",
    "                           morphology = {'type': 'mesh',\n",
    "                                         \"vertices\": (current_mesh.vertex_matrix()).flatten().tolist(),\n",
    "                                         \"faces\": current_mesh.face_matrix().flatten().tolist()},\n",
    "                           subsystem = v['System'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4972480f",
   "metadata": {},
   "source": [
    "## Load neuron data\n",
    "Load a csv fetch from Neuprint about neurons.\n",
    "Load the transcriptome data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a604f20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_list = pd.read_csv('fetched_neurons.csv', index_col=0)\n",
    "nt_df = pd.read_csv('GSE116969_dataTable7b.genes_x_cells_p_expression.modeled_genes.txt', sep = '\\t', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03034b71",
   "metadata": {},
   "source": [
    "## Load Neurons\n",
    "Loading neuorns and any segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a0ff63",
   "metadata": {},
   "outputs": [],
   "source": [
    "swc_dir = 'swc'\n",
    "uname_dict = {}\n",
    "segment_ids = set()\n",
    "added = 0\n",
    "unadded = []\n",
    "to_combine = []\n",
    "loaded_to_segment = []\n",
    "columns = {}\n",
    "\n",
    "neurotransmitter_translation = {'acetylcholine': 'acetylcholine',\n",
    "                                'gaba': 'GABA',\n",
    "                                'glutamate': 'glutamate'}\n",
    "x = 'x'\n",
    "y = 'y'\n",
    "z = 'z'\n",
    "\n",
    "for i, row in tqdm(neuron_list.iterrows()):\n",
    "    if not isinstance(row['instance'], str):\n",
    "        continue\n",
    "    bodyID = row['bodyId']\n",
    "    \n",
    "    name = None\n",
    "    cell_type = None\n",
    "    \n",
    "    segment = False\n",
    "    \n",
    "    info = {}\n",
    "    neurotransmitter = None\n",
    "    column = None\n",
    "    \n",
    "    name = row['instance'].replace('likle', 'like')\n",
    "    if isinstance(row['type'], str):\n",
    "        cell_type = row['type']\n",
    "    else:\n",
    "        cell_type = 'unknown'\n",
    "        name = 'unknown_{}_{}'.format(name, bodyID)\n",
    "    if cell_type != 'unknown':\n",
    "        if ' home' in name:\n",
    "            name = name.replace(' home', '-home')\n",
    "            column = 'home'\n",
    "        elif '-' in name and '-' not in cell_type:\n",
    "            column = name.split('-')[-1]\n",
    "            if column in ['ant', 'post']:\n",
    "                column = name.split('-')[-2]\n",
    "            if (len(column) == 1 and column.isalpha()) or column == 'home':\n",
    "                column = column.upper()\n",
    "            else:\n",
    "                column = None\n",
    "                if name not in uname_dict:\n",
    "                    uname_dict[name] = 0\n",
    "                uname_dict[name] += 1\n",
    "                name = '{}_{}'.format(name, uname_dict[name])\n",
    "        else:\n",
    "            if name not in uname_dict:\n",
    "                uname_dict[name] = 0\n",
    "            uname_dict[name] += 1\n",
    "            name = '{}_{}'.format(name, uname_dict[name])\n",
    "    \n",
    "    added += 1\n",
    "    c_neuropils = row['roiInfo']\n",
    "    arborization = []\n",
    "    \n",
    "    if isinstance(c_neuropils, str):\n",
    "        dendrites = {'{}(R)'.format(neuropil): v['upstream'] for neuropil, v in eval(row['roiInfo']).items() if 'upstream' in v}\n",
    "        axons = {'{}(R)'.format(neuropil): v['downstream'] for neuropil, v in eval(row['roiInfo']).items() if 'downstream' in v}\n",
    "        arborization.append({'dendrites': dendrites, 'axons': axons, 'type': 'neuropil'})\n",
    "    \n",
    "    try:\n",
    "        df = na.load_swc('../fib19/{}/{}.swc'.format(swc_dir, bodyID))\n",
    "        morphology = {'x': (df['x']*0.008).tolist(),\n",
    "                      'y': (df['y']*0.008).tolist(),\n",
    "                      'z': (df['z']*0.008).tolist(),\n",
    "                      'r': (df['r']*0.008).tolist(),\n",
    "                      'parent': df['parent'].tolist(),\n",
    "                      'identifier': [0]*(len(df['x'])),\n",
    "                      'sample': df['sample'].tolist(),\n",
    "                      'type': 'swc'}\n",
    "    except FileNotFoundError:\n",
    "        morphology = None\n",
    "        if segment: # no name, not traced, no morph\n",
    "            to_combine.append(bodyID)\n",
    "            continue\n",
    "        else:\n",
    "            segment = True\n",
    "            loaded_to_segment.append(bodyID)\n",
    "    \n",
    "    if isinstance(row['statusLabel'], str):\n",
    "        info['fib19 Trace Status'] = row['statusLabel']\n",
    "    else:\n",
    "        info['fib19 Trace Status'] = 'Untraced'\n",
    "    \n",
    "    if not segment:\n",
    "        if column is not None:\n",
    "            circuit = None\n",
    "            circuit = columns.get(column, None)\n",
    "            if circuit is None:\n",
    "                circuit = fib19.add_Circuit('Column {}'.format(column), 'Column', neuropil = 'ME(R)')\n",
    "                columns[column] = circuit\n",
    "        else:\n",
    "            circuit = None\n",
    "                \n",
    "        neurotransmitter = []\n",
    "        if cell_type in nt_df.columns or cell_type == 'R8':\n",
    "            if cell_type in ['R{}'.format(i) for i in range(1,7)]:\n",
    "                gene_expression_type = 'R1_6'\n",
    "            elif cell_type == 'R8':\n",
    "                gene_expression_type = 'R8_Rh5'\n",
    "            else:\n",
    "                gene_expression_type = cell_type\n",
    "\n",
    "            if nt_df[gene_expression_type]['Hdc'] > 0.9:\n",
    "                neurotransmitter.append('histamine')\n",
    "            if nt_df[gene_expression_type]['Gad1'] > 0.9:\n",
    "                neurotransmitter.append('GABA')\n",
    "            if nt_df[gene_expression_type]['VAChT'] > 0.9:\n",
    "                neurotransmitter.append('acetylcholine')\n",
    "            if nt_df[gene_expression_type]['VGlut'] > 0.9:\n",
    "                neurotransmitter.append('glutamate')\n",
    "            if nt_df[gene_expression_type]['ple'] > 0.9 \\\n",
    "                    and nt_df[gene_expression_type]['Ddc'] > 0.9 \\\n",
    "                    and nt_df[gene_expression_type]['Vmat'] > 0.9 \\\n",
    "                    and nt_df[gene_expression_type]['DAT'] > 0.9:\n",
    "                neurotransmitter.append('dopamine')\n",
    "        \n",
    "        \n",
    "        fib19.add_Neuron(name, # uname\n",
    "                       cell_type, # name\n",
    "                       referenceId = str(bodyID), #referenceId\n",
    "                       info = info if len(info) else None,\n",
    "                       morphology = morphology,\n",
    "                       arborization = arborization,\n",
    "                       neurotransmitters = neurotransmitter if len(neurotransmitter) else None,\n",
    "                       circuit = circuit)\n",
    "    else:\n",
    "        cell_type = 'segment'\n",
    "        name = 'segment_{}'.format(bodyID)\n",
    "        fib19.add_NeuronFragment(name,\n",
    "                               cell_type,\n",
    "                               referenceId = str(bodyID),\n",
    "                               info = info if len(info) else None,\n",
    "                               morphology = morphology,\n",
    "                               arborization = arborization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed80cb3f",
   "metadata": {},
   "source": [
    "add additional segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3cace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_added = 0\n",
    "for i, row in tqdm(neuron_list.iterrows()):\n",
    "    bodyID = row['bodyId']\n",
    "    if isinstance(row['instance'], str):\n",
    "        continue\n",
    "    if not bodyID in all_swc:\n",
    "        continue\n",
    "\n",
    "    cell_type = 'segment'\n",
    "    name = 'segment_{}'.format(bodyID)\n",
    "\n",
    "    info = {}\n",
    "\n",
    "    added += 1\n",
    "\n",
    "    c_neuropils = row['roiInfo']\n",
    "    arborization = []\n",
    "    if isinstance(c_neuropils, str):\n",
    "        dendrites = {'{}(R)'.format(neuropil): v['upstream'] for neuropil, v in eval(row['roiInfo']).items() if 'upstream' in v}\n",
    "        axons = {'{}(R)'.format(neuropil): v['downstream'] for neuropil, v in eval(row['roiInfo']).items() if 'downstream' in v}\n",
    "        arborization.append({'dendrites': dendrites, 'axons': axons, 'type': 'neuropil'})\n",
    "    \n",
    "    df = na.load_swc('../fib19/{}/{}.swc'.format(swc_dir, bodyID))\n",
    "    morphology = {'x': (df['x']*0.008).tolist(),\n",
    "                  'y': (df['y']*0.008).tolist(),\n",
    "                  'z': (df['z']*0.008).tolist(),\n",
    "                  'r': (df['r']*0.008).tolist(),\n",
    "                  'parent': df['parent'].tolist(),\n",
    "                  'identifier': [0]*(len(df['x'])),\n",
    "                  'sample': df['sample'].tolist(),\n",
    "                  'type': 'swc'}\n",
    "    if isinstance(row['statusLabel'], str):\n",
    "        info['fib19 Trace Status'] = row['statusLabel']\n",
    "    else:\n",
    "        info['fib19 Trace Status'] = 'Untraced'\n",
    "\n",
    "    fib19.add_NeuronFragment(name,\n",
    "                         cell_type,\n",
    "                         referenceId = str(bodyID),\n",
    "                         info = info if len(info) else None,\n",
    "                         morphology = morphology,\n",
    "                         arborization = arborization)\n",
    "    n_added += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6059577",
   "metadata": {},
   "source": [
    "Flush cache of ownership edges. This is needed because creating these edges while creating neuron record turns out to be very time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1c85b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fib19.flush_edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8db1c39",
   "metadata": {},
   "source": [
    "Load neurons into cache so that they can be referred to directly when creating synapses, rather than querying the database many times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1990e9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all the neurons so they can be keyed by their referenceId.\n",
    "neurons = fib19.sql_query('select from NeuronAndFragment').node_objs\n",
    "# set the cache so there is no need for database access.\n",
    "for neuron in neurons:\n",
    "    fib19.set('NeuronAndFragment', neuron.uname, neuron, fib19.default_DataSource)\n",
    "neuron_ref_to_obj = {int(neuron.referenceId): neuron for neuron in neurons}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc032d30",
   "metadata": {},
   "source": [
    "## Create Synapse Records\n",
    "Create synapses if both pre- and post-synaptic neuron/segments are loaded.\n",
    "\n",
    "If not, then combine data of segments pre to a neuron, combine data of segments post to a neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ca1d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = {}\n",
    "morph_dict = {}\n",
    "\n",
    "for chunk in tqdm(pd.read_csv('synapses_all.csv', chunksize=100000)):\n",
    "    for i, row in chunk.iterrows():\n",
    "        pre = int(row['pre_id'])\n",
    "        post = int(row['post_id'])\n",
    "        if pre not in neuron_ref_to_obj:\n",
    "            pre = -1\n",
    "        if post not in neuron_ref_to_obj:\n",
    "            post = -1\n",
    "        if pre == -1 and post == -1:\n",
    "            continue\n",
    "        \n",
    "        pre_conf = np.array(eval(row['pre_confidence']))/1e6\n",
    "        post_conf = np.array(eval(row['post_confidence']))/1e6\n",
    "        NHP = np.sum(np.logical_and(post_conf>=0.7, pre_conf>=0.7))\n",
    "        \n",
    "        if pre == -1:\n",
    "            if post not in tmp:\n",
    "                tmp[post] = {}\n",
    "            if 'pre' not in tmp[post]:\n",
    "                tmp[post]['pre'] = {'pre_x': [], 'pre_y': [], 'pre_z': [], 'post_x': [], 'post_y': [], 'post_z': [],\n",
    "                                    'pre_confidence': [], 'post_confidence': [],\n",
    "                                    'N': 0, 'NHP': 0}\n",
    "            tmp[post]['pre']['pre_x'].append(np.array(eval(row['pre_x']))*0.008)\n",
    "            tmp[post]['pre']['pre_y'].append(np.array(eval(row['pre_y']))*0.008)\n",
    "            tmp[post]['pre']['pre_z'].append(np.array(eval(row['pre_z']))*0.008)\n",
    "            tmp[post]['pre']['post_x'].append(np.array(eval(row['post_x']))*0.008)\n",
    "            tmp[post]['pre']['post_y'].append(np.array(eval(row['post_y']))*0.008)\n",
    "            tmp[post]['pre']['post_z'].append(np.array(eval(row['post_z']))*0.008)\n",
    "            tmp[post]['pre']['pre_confidence'].append(pre_conf)\n",
    "            tmp[post]['pre']['post_confidence'].append(post_conf)\n",
    "            tmp[post]['pre']['N'] += row['N']\n",
    "            tmp[post]['pre']['NHP'] += NHP                        \n",
    "        elif post == -1:\n",
    "            if pre not in tmp:\n",
    "                tmp[pre] = {}\n",
    "            if 'post' not in tmp[pre]:\n",
    "                tmp[pre]['post'] = {'pre_x': [], 'pre_y': [], 'pre_z': [], 'post_x': [], 'post_y': [], 'post_z': [],\n",
    "                                    'pre_confidence': [], 'post_confidence': [],\n",
    "                                    'N': 0, 'NHP': 0}\n",
    "            tmp[pre]['post']['pre_x'].append(np.array(eval(row['pre_x']))*0.008)\n",
    "            tmp[pre]['post']['pre_y'].append(np.array(eval(row['pre_y']))*0.008)\n",
    "            tmp[pre]['post']['pre_z'].append(np.array(eval(row['pre_z']))*0.008)\n",
    "            tmp[pre]['post']['post_x'].append(np.array(eval(row['post_x']))*0.008)\n",
    "            tmp[pre]['post']['post_y'].append(np.array(eval(row['post_y']))*0.008)\n",
    "            tmp[pre]['post']['post_z'].append(np.array(eval(row['post_z']))*0.008)\n",
    "            tmp[pre]['post']['pre_confidence'].append(pre_conf)\n",
    "            tmp[pre]['post']['post_confidence'].append(post_conf)\n",
    "            tmp[pre]['post']['N'] += row['N']\n",
    "            tmp[pre]['post']['NHP'] += NHP\n",
    "        else:\n",
    "            pre_neuron = neuron_ref_to_obj[pre]\n",
    "            post_neuron = neuron_ref_to_obj[post]\n",
    "            c_neuropils = row['neuropils']\n",
    "            arborization = []\n",
    "            neuropils = {}\n",
    "            if isinstance(c_neuropils, str):\n",
    "                arborization.append({'type': 'neuropil',\n",
    "                               'synapses': {\"{}(R)\".format(j.split(':')[0]): int(j.split(':')[1]) \\\n",
    "                                            for j in c_neuropils.split(';') \\\n",
    "                                            if j.split(':')[0] != 'None' and int(j.split(':')[1]) > 0}})\n",
    "            content = {'type': 'swc'}\n",
    "            content['x'] = (np.array(eval(row['pre_x'])+eval(row['post_x']))*0.008).tolist()\n",
    "            content['y'] = (np.array(eval(row['pre_y'])+eval(row['post_y']))*0.008).tolist()\n",
    "            content['z'] = (np.array(eval(row['pre_z'])+eval(row['post_z']))*0.008).tolist()\n",
    "            content['r'] = [0]*len(content['x'])\n",
    "            content['parent'] = [-1]*(len(content['x'])//2) + [i+1 for i in range(len(content['x'])//2)]\n",
    "            content['identifier'] = [7]*(len(content['x'])//2) + [8]*(len(content['x'])//2)\n",
    "            content['sample'] = [i+1 for i in range(len(content['x']))]\n",
    "            content['confidence'] = pre_conf.tolist() + post_conf.tolist()\n",
    "\n",
    "            synapse = fib19.add_Synapse(pre_neuron, post_neuron, N = row['N'], NHP = NHP)\n",
    "            morph_dict[synapse._id] = {'morphology': content,\n",
    "                                       'arborization': arborization}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44c5d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fib19.flush_edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6e6c93",
   "metadata": {},
   "source": [
    "create a notional datasource under which the combined untraced segments are created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a663888",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = '1.0'\n",
    "species = fib19.sql_query('select from Species').node_objs[0]\n",
    "notional_datasource = fib19.add_DataSource('notional', version = version,\n",
    "                                         species = species)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41090920",
   "metadata": {},
   "source": [
    "Create dummpy NeuronFragments and load their synapses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d8f743",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, v in tqdm(tmp.items()):\n",
    "    if 'pre' in v:\n",
    "        post_neuron = neuron_ref_to_obj[n]\n",
    "        cell_type = 'combined_untraced_segments'\n",
    "        name = 'segments_presynaptic_to_{}'.format(post_neuron.uname)\n",
    "        pre_neuron = fib19.add_NeuronFragment(\n",
    "                                     name,\n",
    "                                     cell_type,\n",
    "                                     data_source = notional_datasource)\n",
    "        \n",
    "        content = {'type': 'swc'}\n",
    "        content['x'] = np.concatenate(v['pre']['pre_x'] + v['pre']['post_x']).tolist()\n",
    "        content['y'] = np.concatenate(v['pre']['pre_y'] + v['pre']['post_y']).tolist()\n",
    "        content['z'] = np.concatenate(v['pre']['pre_z'] + v['pre']['post_z']).tolist()\n",
    "        content['r'] = [0]*len(content['x'])\n",
    "        content['parent'] = [-1]*(len(content['x'])//2) + [i+1 for i in range(len(content['x'])//2)]\n",
    "        content['identifier'] = [7]*(len(content['x'])//2) + [8]*(len(content['x'])//2)\n",
    "        content['sample'] = [i+1 for i in range(len(content['x']))]\n",
    "        content['confidence'] = np.concatenate(v['pre']['pre_confidence'] + v['pre']['post_confidence']).tolist()\n",
    "        synapse = fib19.add_Synapse(pre_neuron, post_neuron, N = v['pre']['N'], NHP = v['pre']['NHP'])\n",
    "        morph_dict[synapse._id] = {'morphology': content}\n",
    "    if 'post' in v:\n",
    "        pre_neuron = neuron_ref_to_obj[n]\n",
    "        cell_type = 'combined_untraced_segments'\n",
    "        name = 'segments_postsynaptic_to_{}'.format(pre_neuron.uname)\n",
    "        post_neuron = fib19.add_NeuronFragment(\n",
    "                                     name,\n",
    "                                     cell_type,\n",
    "                                     data_source = notional_datasource)\n",
    "        content = {'type': 'swc'}\n",
    "        content['x'] = np.concatenate(v['post']['pre_x'] + v['post']['post_x']).tolist()\n",
    "        content['y'] = np.concatenate(v['post']['pre_y'] + v['post']['post_y']).tolist()\n",
    "        content['z'] = np.concatenate(v['post']['pre_z'] + v['post']['post_z']).tolist()\n",
    "        content['r'] = [0]*len(content['x'])\n",
    "        content['parent'] = [-1]*(len(content['x'])//2) + [i+1 for i in range(len(content['x'])//2)]\n",
    "        content['identifier'] = [7]*(len(content['x'])//2) + [8]*(len(content['x'])//2)\n",
    "        content['sample'] = [i+1 for i in range(len(content['x']))]\n",
    "        content['confidence'] = np.concatenate(v['post']['pre_confidence'] + v['post']['post_confidence']).tolist()\n",
    "        synapse = fib19.add_Synapse(pre_neuron, post_neuron, N = v['post']['N'], NHP = v['post']['NHP'])\n",
    "        morph_dict[synapse._id] = {'morphology': content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ce8d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "fib19.flush_edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867a7526",
   "metadata": {},
   "source": [
    "load all morphology and arborization data for synapses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f7b1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rid, data in tqdm(morph_dict.items()):\n",
    "    if 'morphology' in data:\n",
    "        fib19.add_morphology(rid, data['morphology'])\n",
    "    if 'arborization' in data:\n",
    "        fib19.add_synapse_arborization(rid, data['arborization'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
